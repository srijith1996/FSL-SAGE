[21/11/24 00:15:49, INFO, CSE_FSL_main.py:<module>():322] Using GPU: True
[21/11/24 00:15:51, INFO, CSE_FSL_main.py:main():120] Aggregation Factor: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]
[21/11/24 00:15:51, INFO, CSE_FSL_main.py:main():125] Random seed: 200
[21/11/24 00:15:51, INFO, CSE_FSL_main.py:main():126] Alignment interval (l): 2
[21/11/24 00:16:18, INFO, CSE_FSL_main.py:main():276]  > R  0, agg. final model, testing loss: 2.29, testing acc: 10.54% ( 1054/10000), training loss: 2.29, training acc: 10.71%
[21/11/24 00:16:44, INFO, CSE_FSL_main.py:main():276]  > R  1, agg. final model, testing loss: 1.98, testing acc: 23.65% ( 2365/10000), training loss: 2.04, training acc: 21.60%
[21/11/24 00:17:09, INFO, CSE_FSL_main.py:main():276]  > R  2, agg. final model, testing loss: 1.87, testing acc: 29.54% ( 2954/10000), training loss: 1.93, training acc: 26.35%
[21/11/24 00:17:34, INFO, CSE_FSL_main.py:main():276]  > R  3, agg. final model, testing loss: 1.84, testing acc: 31.68% ( 3168/10000), training loss: 1.92, training acc: 27.63%
[21/11/24 00:18:00, INFO, CSE_FSL_main.py:main():276]  > R  4, agg. final model, testing loss: 1.71, testing acc: 36.02% ( 3602/10000), training loss: 1.83, training acc: 31.07%
[21/11/24 00:18:25, INFO, CSE_FSL_main.py:main():276]  > R  5, agg. final model, testing loss: 1.66, testing acc: 38.86% ( 3886/10000), training loss: 1.77, training acc: 34.39%
[21/11/24 00:18:50, INFO, CSE_FSL_main.py:main():276]  > R  6, agg. final model, testing loss: 1.63, testing acc: 40.20% ( 4020/10000), training loss: 1.75, training acc: 35.50%
[21/11/24 00:19:15, INFO, CSE_FSL_main.py:main():276]  > R  7, agg. final model, testing loss: 1.60, testing acc: 40.30% ( 4030/10000), training loss: 1.74, training acc: 35.01%
[21/11/24 00:19:40, INFO, CSE_FSL_main.py:main():276]  > R  8, agg. final model, testing loss: 1.56, testing acc: 42.56% ( 4256/10000), training loss: 1.70, training acc: 37.56%
[21/11/24 00:20:05, INFO, CSE_FSL_main.py:main():276]  > R  9, agg. final model, testing loss: 1.56, testing acc: 42.53% ( 4253/10000), training loss: 1.69, training acc: 38.33%
[21/11/24 00:20:30, INFO, CSE_FSL_main.py:main():276]  > R 10, agg. final model, testing loss: 1.52, testing acc: 44.65% ( 4465/10000), training loss: 1.66, training acc: 38.76%
[21/11/24 00:20:55, INFO, CSE_FSL_main.py:main():276]  > R 11, agg. final model, testing loss: 1.49, testing acc: 45.28% ( 4528/10000), training loss: 1.62, training acc: 40.34%
[21/11/24 00:21:20, INFO, CSE_FSL_main.py:main():276]  > R 12, agg. final model, testing loss: 1.47, testing acc: 46.09% ( 4609/10000), training loss: 1.61, training acc: 40.99%
[21/11/24 00:21:45, INFO, CSE_FSL_main.py:main():276]  > R 13, agg. final model, testing loss: 1.46, testing acc: 47.07% ( 4707/10000), training loss: 1.59, training acc: 41.96%
[21/11/24 00:22:10, INFO, CSE_FSL_main.py:main():276]  > R 14, agg. final model, testing loss: 1.45, testing acc: 47.40% ( 4740/10000), training loss: 1.59, training acc: 41.60%
[21/11/24 00:22:35, INFO, CSE_FSL_main.py:main():276]  > R 15, agg. final model, testing loss: 1.41, testing acc: 48.83% ( 4883/10000), training loss: 1.55, training acc: 43.60%
[21/11/24 00:23:00, INFO, CSE_FSL_main.py:main():276]  > R 16, agg. final model, testing loss: 1.40, testing acc: 48.69% ( 4869/10000), training loss: 1.54, training acc: 43.81%
[21/11/24 00:23:26, INFO, CSE_FSL_main.py:main():276]  > R 17, agg. final model, testing loss: 1.38, testing acc: 49.97% ( 4997/10000), training loss: 1.51, training acc: 44.93%
[21/11/24 00:23:51, INFO, CSE_FSL_main.py:main():276]  > R 18, agg. final model, testing loss: 1.37, testing acc: 50.32% ( 5032/10000), training loss: 1.51, training acc: 44.99%
[21/11/24 00:24:16, INFO, CSE_FSL_main.py:main():276]  > R 19, agg. final model, testing loss: 1.35, testing acc: 51.27% ( 5127/10000), training loss: 1.48, training acc: 46.43%
[21/11/24 00:24:41, INFO, CSE_FSL_main.py:main():276]  > R 20, agg. final model, testing loss: 1.33, testing acc: 52.10% ( 5210/10000), training loss: 1.48, training acc: 46.60%
[21/11/24 00:25:06, INFO, CSE_FSL_main.py:main():276]  > R 21, agg. final model, testing loss: 1.33, testing acc: 52.23% ( 5223/10000), training loss: 1.46, training acc: 47.11%
[21/11/24 00:25:31, INFO, CSE_FSL_main.py:main():276]  > R 22, agg. final model, testing loss: 1.29, testing acc: 53.41% ( 5341/10000), training loss: 1.43, training acc: 48.17%
[21/11/24 00:25:56, INFO, CSE_FSL_main.py:main():276]  > R 23, agg. final model, testing loss: 1.29, testing acc: 53.61% ( 5361/10000), training loss: 1.42, training acc: 48.77%
[21/11/24 00:26:21, INFO, CSE_FSL_main.py:main():276]  > R 24, agg. final model, testing loss: 1.26, testing acc: 55.41% ( 5541/10000), training loss: 1.40, training acc: 49.52%
[21/11/24 00:26:46, INFO, CSE_FSL_main.py:main():276]  > R 25, agg. final model, testing loss: 1.25, testing acc: 55.61% ( 5561/10000), training loss: 1.38, training acc: 50.18%
[21/11/24 00:27:11, INFO, CSE_FSL_main.py:main():276]  > R 26, agg. final model, testing loss: 1.24, testing acc: 56.23% ( 5623/10000), training loss: 1.38, training acc: 50.54%
[21/11/24 00:27:36, INFO, CSE_FSL_main.py:main():276]  > R 27, agg. final model, testing loss: 1.25, testing acc: 55.48% ( 5548/10000), training loss: 1.38, training acc: 49.93%
[21/11/24 00:28:01, INFO, CSE_FSL_main.py:main():276]  > R 28, agg. final model, testing loss: 1.19, testing acc: 57.73% ( 5773/10000), training loss: 1.33, training acc: 52.35%
[21/11/24 00:28:26, INFO, CSE_FSL_main.py:main():276]  > R 29, agg. final model, testing loss: 1.18, testing acc: 58.43% ( 5843/10000), training loss: 1.32, training acc: 52.80%
[21/11/24 00:28:52, INFO, CSE_FSL_main.py:main():276]  > R 30, agg. final model, testing loss: 1.18, testing acc: 58.08% ( 5808/10000), training loss: 1.31, training acc: 52.88%
[21/11/24 00:29:17, INFO, CSE_FSL_main.py:main():276]  > R 31, agg. final model, testing loss: 1.15, testing acc: 59.08% ( 5908/10000), training loss: 1.30, training acc: 53.51%
[21/11/24 00:29:42, INFO, CSE_FSL_main.py:main():276]  > R 32, agg. final model, testing loss: 1.15, testing acc: 59.14% ( 5914/10000), training loss: 1.30, training acc: 53.45%
[21/11/24 00:30:07, INFO, CSE_FSL_main.py:main():276]  > R 33, agg. final model, testing loss: 1.13, testing acc: 60.43% ( 6043/10000), training loss: 1.27, training acc: 54.21%
[21/11/24 00:30:32, INFO, CSE_FSL_main.py:main():276]  > R 34, agg. final model, testing loss: 1.12, testing acc: 60.44% ( 6044/10000), training loss: 1.26, training acc: 54.86%
[21/11/24 00:30:57, INFO, CSE_FSL_main.py:main():276]  > R 35, agg. final model, testing loss: 1.09, testing acc: 61.84% ( 6184/10000), training loss: 1.23, training acc: 55.98%
[21/11/24 00:31:22, INFO, CSE_FSL_main.py:main():276]  > R 36, agg. final model, testing loss: 1.09, testing acc: 61.88% ( 6188/10000), training loss: 1.25, training acc: 55.80%
[21/11/24 00:31:47, INFO, CSE_FSL_main.py:main():276]  > R 37, agg. final model, testing loss: 1.08, testing acc: 62.36% ( 6236/10000), training loss: 1.23, training acc: 56.45%
[21/11/24 00:32:12, INFO, CSE_FSL_main.py:main():276]  > R 38, agg. final model, testing loss: 1.06, testing acc: 62.49% ( 6249/10000), training loss: 1.21, training acc: 56.90%
[21/11/24 00:32:37, INFO, CSE_FSL_main.py:main():276]  > R 39, agg. final model, testing loss: 1.05, testing acc: 63.75% ( 6375/10000), training loss: 1.19, training acc: 57.67%
[21/11/24 00:33:02, INFO, CSE_FSL_main.py:main():276]  > R 40, agg. final model, testing loss: 1.05, testing acc: 62.95% ( 6295/10000), training loss: 1.18, training acc: 58.04%
[21/11/24 00:33:27, INFO, CSE_FSL_main.py:main():276]  > R 41, agg. final model, testing loss: 1.05, testing acc: 62.88% ( 6288/10000), training loss: 1.18, training acc: 57.93%
[21/11/24 00:33:52, INFO, CSE_FSL_main.py:main():276]  > R 42, agg. final model, testing loss: 1.04, testing acc: 64.10% ( 6410/10000), training loss: 1.17, training acc: 58.68%
[21/11/24 00:34:17, INFO, CSE_FSL_main.py:main():276]  > R 43, agg. final model, testing loss: 1.03, testing acc: 63.98% ( 6398/10000), training loss: 1.17, training acc: 58.60%
[21/11/24 00:34:42, INFO, CSE_FSL_main.py:main():276]  > R 44, agg. final model, testing loss: 1.03, testing acc: 64.51% ( 6451/10000), training loss: 1.17, training acc: 58.46%
[21/11/24 00:35:07, INFO, CSE_FSL_main.py:main():276]  > R 45, agg. final model, testing loss: 1.02, testing acc: 64.25% ( 6425/10000), training loss: 1.14, training acc: 59.59%
[21/11/24 00:35:33, INFO, CSE_FSL_main.py:main():276]  > R 46, agg. final model, testing loss: 1.00, testing acc: 65.33% ( 6533/10000), training loss: 1.13, training acc: 59.60%
[21/11/24 00:35:58, INFO, CSE_FSL_main.py:main():276]  > R 47, agg. final model, testing loss: 0.99, testing acc: 65.67% ( 6567/10000), training loss: 1.12, training acc: 60.46%
[21/11/24 00:36:23, INFO, CSE_FSL_main.py:main():276]  > R 48, agg. final model, testing loss: 0.99, testing acc: 65.36% ( 6536/10000), training loss: 1.13, training acc: 59.91%
[21/11/24 00:36:48, INFO, CSE_FSL_main.py:main():276]  > R 49, agg. final model, testing loss: 0.99, testing acc: 65.74% ( 6574/10000), training loss: 1.12, training acc: 60.45%
[21/11/24 00:37:13, INFO, CSE_FSL_main.py:main():276]  > R 50, agg. final model, testing loss: 0.99, testing acc: 65.83% ( 6583/10000), training loss: 1.13, training acc: 60.10%
[21/11/24 00:37:38, INFO, CSE_FSL_main.py:main():276]  > R 51, agg. final model, testing loss: 0.96, testing acc: 66.73% ( 6673/10000), training loss: 1.10, training acc: 61.01%
[21/11/24 00:38:03, INFO, CSE_FSL_main.py:main():276]  > R 52, agg. final model, testing loss: 0.97, testing acc: 65.89% ( 6589/10000), training loss: 1.11, training acc: 61.08%
[21/11/24 00:38:28, INFO, CSE_FSL_main.py:main():276]  > R 53, agg. final model, testing loss: 0.98, testing acc: 66.13% ( 6613/10000), training loss: 1.13, training acc: 60.27%
[21/11/24 00:38:53, INFO, CSE_FSL_main.py:main():276]  > R 54, agg. final model, testing loss: 0.96, testing acc: 66.96% ( 6696/10000), training loss: 1.08, training acc: 62.19%
[21/11/24 00:39:18, INFO, CSE_FSL_main.py:main():276]  > R 55, agg. final model, testing loss: 0.95, testing acc: 66.87% ( 6687/10000), training loss: 1.08, training acc: 61.96%
[21/11/24 00:39:43, INFO, CSE_FSL_main.py:main():276]  > R 56, agg. final model, testing loss: 0.93, testing acc: 67.85% ( 6785/10000), training loss: 1.07, training acc: 62.27%
[21/11/24 00:40:08, INFO, CSE_FSL_main.py:main():276]  > R 57, agg. final model, testing loss: 0.93, testing acc: 67.91% ( 6791/10000), training loss: 1.04, training acc: 63.27%
[21/11/24 00:40:33, INFO, CSE_FSL_main.py:main():276]  > R 58, agg. final model, testing loss: 0.93, testing acc: 67.72% ( 6772/10000), training loss: 1.08, training acc: 62.10%
[21/11/24 00:40:58, INFO, CSE_FSL_main.py:main():276]  > R 59, agg. final model, testing loss: 0.95, testing acc: 66.64% ( 6664/10000), training loss: 1.08, training acc: 61.90%
[21/11/24 00:41:23, INFO, CSE_FSL_main.py:main():276]  > R 60, agg. final model, testing loss: 0.93, testing acc: 67.69% ( 6769/10000), training loss: 1.06, training acc: 62.51%
[21/11/24 00:41:49, INFO, CSE_FSL_main.py:main():276]  > R 61, agg. final model, testing loss: 0.94, testing acc: 66.98% ( 6698/10000), training loss: 1.07, training acc: 62.12%
[21/11/24 00:42:14, INFO, CSE_FSL_main.py:main():276]  > R 62, agg. final model, testing loss: 0.92, testing acc: 67.98% ( 6798/10000), training loss: 1.04, training acc: 63.37%
[21/11/24 00:42:39, INFO, CSE_FSL_main.py:main():276]  > R 63, agg. final model, testing loss: 0.90, testing acc: 68.79% ( 6879/10000), training loss: 1.02, training acc: 64.11%
[21/11/24 00:43:04, INFO, CSE_FSL_main.py:main():276]  > R 64, agg. final model, testing loss: 0.90, testing acc: 68.63% ( 6863/10000), training loss: 1.03, training acc: 64.28%
[21/11/24 00:43:29, INFO, CSE_FSL_main.py:main():276]  > R 65, agg. final model, testing loss: 0.90, testing acc: 68.97% ( 6897/10000), training loss: 1.02, training acc: 64.47%
[21/11/24 00:43:54, INFO, CSE_FSL_main.py:main():276]  > R 66, agg. final model, testing loss: 0.89, testing acc: 69.22% ( 6922/10000), training loss: 1.00, training acc: 64.95%
[21/11/24 00:44:19, INFO, CSE_FSL_main.py:main():276]  > R 67, agg. final model, testing loss: 0.90, testing acc: 68.78% ( 6878/10000), training loss: 1.02, training acc: 64.06%
[21/11/24 00:44:44, INFO, CSE_FSL_main.py:main():276]  > R 68, agg. final model, testing loss: 0.89, testing acc: 69.04% ( 6904/10000), training loss: 1.01, training acc: 64.58%
[21/11/24 00:45:09, INFO, CSE_FSL_main.py:main():276]  > R 69, agg. final model, testing loss: 0.87, testing acc: 69.87% ( 6987/10000), training loss: 1.00, training acc: 65.03%
[21/11/24 00:45:34, INFO, CSE_FSL_main.py:main():276]  > R 70, agg. final model, testing loss: 0.89, testing acc: 69.22% ( 6922/10000), training loss: 1.01, training acc: 64.77%
[21/11/24 00:45:59, INFO, CSE_FSL_main.py:main():276]  > R 71, agg. final model, testing loss: 0.85, testing acc: 70.73% ( 7073/10000), training loss: 0.97, training acc: 66.32%
[21/11/24 00:46:24, INFO, CSE_FSL_main.py:main():276]  > R 72, agg. final model, testing loss: 0.88, testing acc: 69.65% ( 6965/10000), training loss: 0.99, training acc: 65.12%
[21/11/24 00:46:49, INFO, CSE_FSL_main.py:main():276]  > R 73, agg. final model, testing loss: 0.88, testing acc: 70.00% ( 7000/10000), training loss: 1.01, training acc: 64.19%
[21/11/24 00:47:15, INFO, CSE_FSL_main.py:main():276]  > R 74, agg. final model, testing loss: 0.86, testing acc: 70.19% ( 7019/10000), training loss: 1.00, training acc: 64.71%
[21/11/24 00:47:40, INFO, CSE_FSL_main.py:main():276]  > R 75, agg. final model, testing loss: 0.85, testing acc: 70.44% ( 7044/10000), training loss: 0.97, training acc: 66.05%
[21/11/24 00:48:05, INFO, CSE_FSL_main.py:main():276]  > R 76, agg. final model, testing loss: 0.85, testing acc: 70.30% ( 7030/10000), training loss: 0.97, training acc: 66.07%
[21/11/24 00:48:30, INFO, CSE_FSL_main.py:main():276]  > R 77, agg. final model, testing loss: 0.85, testing acc: 70.42% ( 7042/10000), training loss: 0.96, training acc: 66.28%
[21/11/24 00:48:55, INFO, CSE_FSL_main.py:main():276]  > R 78, agg. final model, testing loss: 0.85, testing acc: 70.86% ( 7086/10000), training loss: 0.97, training acc: 66.23%
[21/11/24 00:49:20, INFO, CSE_FSL_main.py:main():276]  > R 79, agg. final model, testing loss: 0.85, testing acc: 69.95% ( 6995/10000), training loss: 0.96, training acc: 66.31%
[21/11/24 00:49:45, INFO, CSE_FSL_main.py:main():276]  > R 80, agg. final model, testing loss: 0.85, testing acc: 70.61% ( 7061/10000), training loss: 0.96, training acc: 66.58%
[21/11/24 00:50:10, INFO, CSE_FSL_main.py:main():276]  > R 81, agg. final model, testing loss: 0.84, testing acc: 70.99% ( 7099/10000), training loss: 0.95, training acc: 66.52%
[21/11/24 00:50:35, INFO, CSE_FSL_main.py:main():276]  > R 82, agg. final model, testing loss: 0.84, testing acc: 70.85% ( 7085/10000), training loss: 0.94, training acc: 66.91%
[21/11/24 00:51:00, INFO, CSE_FSL_main.py:main():276]  > R 83, agg. final model, testing loss: 0.83, testing acc: 71.25% ( 7125/10000), training loss: 0.93, training acc: 67.32%
[21/11/24 00:51:25, INFO, CSE_FSL_main.py:main():276]  > R 84, agg. final model, testing loss: 0.83, testing acc: 70.64% ( 7064/10000), training loss: 0.94, training acc: 66.79%
[21/11/24 00:51:50, INFO, CSE_FSL_main.py:main():276]  > R 85, agg. final model, testing loss: 0.84, testing acc: 71.19% ( 7119/10000), training loss: 0.94, training acc: 66.95%
[21/11/24 00:52:15, INFO, CSE_FSL_main.py:main():276]  > R 86, agg. final model, testing loss: 0.84, testing acc: 70.71% ( 7071/10000), training loss: 0.95, training acc: 66.49%
[21/11/24 00:52:40, INFO, CSE_FSL_main.py:main():276]  > R 87, agg. final model, testing loss: 0.83, testing acc: 71.31% ( 7131/10000), training loss: 0.93, training acc: 67.45%
[21/11/24 00:53:06, INFO, CSE_FSL_main.py:main():276]  > R 88, agg. final model, testing loss: 0.84, testing acc: 71.39% ( 7139/10000), training loss: 0.95, training acc: 66.55%
[21/11/24 00:53:31, INFO, CSE_FSL_main.py:main():276]  > R 89, agg. final model, testing loss: 0.83, testing acc: 71.19% ( 7119/10000), training loss: 0.94, training acc: 67.18%
[21/11/24 00:53:56, INFO, CSE_FSL_main.py:main():276]  > R 90, agg. final model, testing loss: 0.83, testing acc: 71.30% ( 7130/10000), training loss: 0.93, training acc: 67.25%
[21/11/24 00:54:21, INFO, CSE_FSL_main.py:main():276]  > R 91, agg. final model, testing loss: 0.82, testing acc: 71.38% ( 7138/10000), training loss: 0.92, training acc: 67.45%
[21/11/24 00:54:46, INFO, CSE_FSL_main.py:main():276]  > R 92, agg. final model, testing loss: 0.85, testing acc: 70.24% ( 7024/10000), training loss: 0.94, training acc: 66.67%
[21/11/24 00:55:11, INFO, CSE_FSL_main.py:main():276]  > R 93, agg. final model, testing loss: 0.81, testing acc: 71.74% ( 7174/10000), training loss: 0.91, training acc: 68.02%
[21/11/24 00:55:36, INFO, CSE_FSL_main.py:main():276]  > R 94, agg. final model, testing loss: 0.82, testing acc: 71.22% ( 7122/10000), training loss: 0.92, training acc: 67.87%
[21/11/24 00:56:01, INFO, CSE_FSL_main.py:main():276]  > R 95, agg. final model, testing loss: 0.80, testing acc: 72.29% ( 7229/10000), training loss: 0.90, training acc: 68.37%
[21/11/24 00:56:26, INFO, CSE_FSL_main.py:main():276]  > R 96, agg. final model, testing loss: 0.82, testing acc: 71.31% ( 7131/10000), training loss: 0.92, training acc: 67.64%
[21/11/24 00:56:51, INFO, CSE_FSL_main.py:main():276]  > R 97, agg. final model, testing loss: 0.82, testing acc: 71.28% ( 7128/10000), training loss: 0.91, training acc: 68.04%
[21/11/24 00:57:16, INFO, CSE_FSL_main.py:main():276]  > R 98, agg. final model, testing loss: 0.81, testing acc: 72.15% ( 7215/10000), training loss: 0.89, training acc: 69.03%
[21/11/24 00:57:42, INFO, CSE_FSL_main.py:main():276]  > R 99, agg. final model, testing loss: 0.80, testing acc: 72.16% ( 7216/10000), training loss: 0.89, training acc: 68.70%
[21/11/24 00:58:07, INFO, CSE_FSL_main.py:main():276]  > R 100, agg. final model, testing loss: 0.80, testing acc: 72.32% ( 7232/10000), training loss: 0.88, training acc: 69.04%
[21/11/24 00:58:32, INFO, CSE_FSL_main.py:main():276]  > R 101, agg. final model, testing loss: 0.80, testing acc: 72.20% ( 7220/10000), training loss: 0.89, training acc: 68.74%
[21/11/24 00:58:57, INFO, CSE_FSL_main.py:main():276]  > R 102, agg. final model, testing loss: 0.79, testing acc: 72.24% ( 7224/10000), training loss: 0.88, training acc: 69.09%
[21/11/24 00:59:22, INFO, CSE_FSL_main.py:main():276]  > R 103, agg. final model, testing loss: 0.82, testing acc: 70.90% ( 7090/10000), training loss: 0.91, training acc: 68.04%
[21/11/24 00:59:47, INFO, CSE_FSL_main.py:main():276]  > R 104, agg. final model, testing loss: 0.81, testing acc: 71.68% ( 7168/10000), training loss: 0.89, training acc: 69.16%
[21/11/24 01:00:12, INFO, CSE_FSL_main.py:main():276]  > R 105, agg. final model, testing loss: 0.81, testing acc: 72.16% ( 7216/10000), training loss: 0.89, training acc: 68.55%
[21/11/24 01:00:37, INFO, CSE_FSL_main.py:main():276]  > R 106, agg. final model, testing loss: 0.80, testing acc: 72.01% ( 7201/10000), training loss: 0.89, training acc: 68.81%
[21/11/24 01:01:02, INFO, CSE_FSL_main.py:main():276]  > R 107, agg. final model, testing loss: 0.79, testing acc: 72.55% ( 7255/10000), training loss: 0.88, training acc: 68.97%
[21/11/24 01:01:27, INFO, CSE_FSL_main.py:main():276]  > R 108, agg. final model, testing loss: 0.79, testing acc: 72.23% ( 7223/10000), training loss: 0.88, training acc: 68.86%
[21/11/24 01:01:52, INFO, CSE_FSL_main.py:main():276]  > R 109, agg. final model, testing loss: 0.79, testing acc: 72.26% ( 7226/10000), training loss: 0.88, training acc: 69.40%
[21/11/24 01:02:17, INFO, CSE_FSL_main.py:main():276]  > R 110, agg. final model, testing loss: 0.79, testing acc: 72.35% ( 7235/10000), training loss: 0.88, training acc: 68.97%
[21/11/24 01:02:43, INFO, CSE_FSL_main.py:main():276]  > R 111, agg. final model, testing loss: 0.78, testing acc: 73.03% ( 7303/10000), training loss: 0.87, training acc: 69.83%
[21/11/24 01:03:08, INFO, CSE_FSL_main.py:main():276]  > R 112, agg. final model, testing loss: 0.80, testing acc: 72.59% ( 7259/10000), training loss: 0.87, training acc: 69.49%
[21/11/24 01:03:33, INFO, CSE_FSL_main.py:main():276]  > R 113, agg. final model, testing loss: 0.78, testing acc: 72.90% ( 7290/10000), training loss: 0.86, training acc: 69.73%
[21/11/24 01:03:58, INFO, CSE_FSL_main.py:main():276]  > R 114, agg. final model, testing loss: 0.79, testing acc: 72.53% ( 7253/10000), training loss: 0.87, training acc: 69.82%
[21/11/24 01:04:23, INFO, CSE_FSL_main.py:main():276]  > R 115, agg. final model, testing loss: 0.80, testing acc: 72.20% ( 7220/10000), training loss: 0.88, training acc: 69.07%
[21/11/24 01:04:48, INFO, CSE_FSL_main.py:main():276]  > R 116, agg. final model, testing loss: 0.78, testing acc: 72.66% ( 7266/10000), training loss: 0.85, training acc: 70.10%
[21/11/24 01:05:13, INFO, CSE_FSL_main.py:main():276]  > R 117, agg. final model, testing loss: 0.78, testing acc: 72.57% ( 7257/10000), training loss: 0.86, training acc: 69.83%
[21/11/24 01:05:38, INFO, CSE_FSL_main.py:main():276]  > R 118, agg. final model, testing loss: 0.78, testing acc: 73.09% ( 7309/10000), training loss: 0.85, training acc: 70.27%
[21/11/24 01:06:03, INFO, CSE_FSL_main.py:main():276]  > R 119, agg. final model, testing loss: 0.78, testing acc: 72.93% ( 7293/10000), training loss: 0.87, training acc: 69.60%
[21/11/24 01:06:28, INFO, CSE_FSL_main.py:main():276]  > R 120, agg. final model, testing loss: 0.78, testing acc: 72.56% ( 7256/10000), training loss: 0.86, training acc: 69.89%
[21/11/24 01:06:53, INFO, CSE_FSL_main.py:main():276]  > R 121, agg. final model, testing loss: 0.77, testing acc: 72.85% ( 7285/10000), training loss: 0.85, training acc: 70.23%
[21/11/24 01:07:18, INFO, CSE_FSL_main.py:main():276]  > R 122, agg. final model, testing loss: 0.78, testing acc: 72.81% ( 7281/10000), training loss: 0.85, training acc: 70.50%
[21/11/24 01:07:43, INFO, CSE_FSL_main.py:main():276]  > R 123, agg. final model, testing loss: 0.78, testing acc: 72.72% ( 7272/10000), training loss: 0.84, training acc: 70.72%
[21/11/24 01:08:09, INFO, CSE_FSL_main.py:main():276]  > R 124, agg. final model, testing loss: 0.77, testing acc: 73.32% ( 7332/10000), training loss: 0.84, training acc: 70.70%
[21/11/24 01:08:34, INFO, CSE_FSL_main.py:main():276]  > R 125, agg. final model, testing loss: 0.76, testing acc: 73.64% ( 7364/10000), training loss: 0.82, training acc: 71.06%
[21/11/24 01:08:59, INFO, CSE_FSL_main.py:main():276]  > R 126, agg. final model, testing loss: 0.78, testing acc: 73.18% ( 7318/10000), training loss: 0.84, training acc: 70.56%
[21/11/24 01:09:24, INFO, CSE_FSL_main.py:main():276]  > R 127, agg. final model, testing loss: 0.77, testing acc: 73.26% ( 7326/10000), training loss: 0.85, training acc: 70.20%
[21/11/24 01:09:49, INFO, CSE_FSL_main.py:main():276]  > R 128, agg. final model, testing loss: 0.77, testing acc: 73.56% ( 7356/10000), training loss: 0.84, training acc: 70.55%
[21/11/24 01:10:14, INFO, CSE_FSL_main.py:main():276]  > R 129, agg. final model, testing loss: 0.77, testing acc: 73.12% ( 7312/10000), training loss: 0.84, training acc: 70.71%
[21/11/24 01:10:39, INFO, CSE_FSL_main.py:main():276]  > R 130, agg. final model, testing loss: 0.78, testing acc: 72.92% ( 7292/10000), training loss: 0.85, training acc: 70.14%
[21/11/24 01:11:04, INFO, CSE_FSL_main.py:main():276]  > R 131, agg. final model, testing loss: 0.78, testing acc: 73.33% ( 7333/10000), training loss: 0.84, training acc: 70.88%
[21/11/24 01:11:29, INFO, CSE_FSL_main.py:main():276]  > R 132, agg. final model, testing loss: 0.75, testing acc: 74.25% ( 7425/10000), training loss: 0.82, training acc: 71.42%
[21/11/24 01:11:54, INFO, CSE_FSL_main.py:main():276]  > R 133, agg. final model, testing loss: 0.76, testing acc: 74.02% ( 7402/10000), training loss: 0.83, training acc: 70.82%
[21/11/24 01:12:19, INFO, CSE_FSL_main.py:main():276]  > R 134, agg. final model, testing loss: 0.78, testing acc: 73.38% ( 7338/10000), training loss: 0.83, training acc: 71.22%
[21/11/24 01:12:44, INFO, CSE_FSL_main.py:main():276]  > R 135, agg. final model, testing loss: 0.77, testing acc: 73.40% ( 7340/10000), training loss: 0.83, training acc: 70.90%
[21/11/24 01:13:09, INFO, CSE_FSL_main.py:main():276]  > R 136, agg. final model, testing loss: 0.76, testing acc: 73.34% ( 7334/10000), training loss: 0.83, training acc: 71.01%
[21/11/24 01:13:34, INFO, CSE_FSL_main.py:main():276]  > R 137, agg. final model, testing loss: 0.77, testing acc: 73.06% ( 7306/10000), training loss: 0.84, training acc: 70.79%
[21/11/24 01:14:00, INFO, CSE_FSL_main.py:main():276]  > R 138, agg. final model, testing loss: 0.76, testing acc: 73.70% ( 7370/10000), training loss: 0.83, training acc: 71.23%
[21/11/24 01:14:25, INFO, CSE_FSL_main.py:main():276]  > R 139, agg. final model, testing loss: 0.75, testing acc: 73.78% ( 7378/10000), training loss: 0.80, training acc: 71.74%
[21/11/24 01:14:50, INFO, CSE_FSL_main.py:main():276]  > R 140, agg. final model, testing loss: 0.75, testing acc: 73.35% ( 7335/10000), training loss: 0.82, training acc: 71.13%
[21/11/24 01:15:15, INFO, CSE_FSL_main.py:main():276]  > R 141, agg. final model, testing loss: 0.75, testing acc: 73.92% ( 7392/10000), training loss: 0.81, training acc: 71.96%
[21/11/24 01:15:40, INFO, CSE_FSL_main.py:main():276]  > R 142, agg. final model, testing loss: 0.76, testing acc: 73.89% ( 7389/10000), training loss: 0.81, training acc: 71.48%
[21/11/24 01:16:05, INFO, CSE_FSL_main.py:main():276]  > R 143, agg. final model, testing loss: 0.76, testing acc: 73.63% ( 7363/10000), training loss: 0.82, training acc: 71.54%
[21/11/24 01:16:30, INFO, CSE_FSL_main.py:main():276]  > R 144, agg. final model, testing loss: 0.76, testing acc: 73.59% ( 7359/10000), training loss: 0.81, training acc: 71.57%
[21/11/24 01:16:55, INFO, CSE_FSL_main.py:main():276]  > R 145, agg. final model, testing loss: 0.75, testing acc: 74.09% ( 7409/10000), training loss: 0.81, training acc: 71.46%
[21/11/24 01:17:20, INFO, CSE_FSL_main.py:main():276]  > R 146, agg. final model, testing loss: 0.77, testing acc: 73.02% ( 7302/10000), training loss: 0.82, training acc: 70.98%
[21/11/24 01:17:45, INFO, CSE_FSL_main.py:main():276]  > R 147, agg. final model, testing loss: 0.75, testing acc: 73.87% ( 7387/10000), training loss: 0.80, training acc: 71.78%
[21/11/24 01:18:11, INFO, CSE_FSL_main.py:main():276]  > R 148, agg. final model, testing loss: 0.74, testing acc: 74.33% ( 7433/10000), training loss: 0.80, training acc: 71.87%
[21/11/24 01:18:36, INFO, CSE_FSL_main.py:main():276]  > R 149, agg. final model, testing loss: 0.75, testing acc: 73.91% ( 7391/10000), training loss: 0.79, training acc: 72.28%
[21/11/24 01:19:01, INFO, CSE_FSL_main.py:main():276]  > R 150, agg. final model, testing loss: 0.76, testing acc: 73.31% ( 7331/10000), training loss: 0.81, training acc: 71.73%
[21/11/24 01:19:26, INFO, CSE_FSL_main.py:main():276]  > R 151, agg. final model, testing loss: 0.76, testing acc: 74.09% ( 7409/10000), training loss: 0.81, training acc: 71.84%
[21/11/24 01:19:52, INFO, CSE_FSL_main.py:main():276]  > R 152, agg. final model, testing loss: 0.75, testing acc: 73.97% ( 7397/10000), training loss: 0.79, training acc: 72.14%
[21/11/24 01:20:17, INFO, CSE_FSL_main.py:main():276]  > R 153, agg. final model, testing loss: 0.76, testing acc: 73.11% ( 7311/10000), training loss: 0.81, training acc: 71.70%
[21/11/24 01:20:42, INFO, CSE_FSL_main.py:main():276]  > R 154, agg. final model, testing loss: 0.77, testing acc: 73.00% ( 7300/10000), training loss: 0.81, training acc: 71.66%
[21/11/24 01:21:07, INFO, CSE_FSL_main.py:main():276]  > R 155, agg. final model, testing loss: 0.75, testing acc: 74.31% ( 7431/10000), training loss: 0.82, training acc: 71.43%
[21/11/24 01:21:33, INFO, CSE_FSL_main.py:main():276]  > R 156, agg. final model, testing loss: 0.75, testing acc: 74.12% ( 7412/10000), training loss: 0.81, training acc: 71.85%
[21/11/24 01:21:58, INFO, CSE_FSL_main.py:main():276]  > R 157, agg. final model, testing loss: 0.75, testing acc: 73.97% ( 7397/10000), training loss: 0.80, training acc: 71.93%
[21/11/24 01:22:23, INFO, CSE_FSL_main.py:main():276]  > R 158, agg. final model, testing loss: 0.74, testing acc: 74.69% ( 7469/10000), training loss: 0.79, training acc: 72.27%
[21/11/24 01:22:48, INFO, CSE_FSL_main.py:main():276]  > R 159, agg. final model, testing loss: 0.75, testing acc: 73.63% ( 7363/10000), training loss: 0.79, training acc: 72.19%
[21/11/24 01:23:13, INFO, CSE_FSL_main.py:main():276]  > R 160, agg. final model, testing loss: 0.75, testing acc: 74.25% ( 7425/10000), training loss: 0.80, training acc: 71.88%
[21/11/24 01:23:39, INFO, CSE_FSL_main.py:main():276]  > R 161, agg. final model, testing loss: 0.75, testing acc: 74.53% ( 7453/10000), training loss: 0.79, training acc: 72.42%
[21/11/24 01:24:04, INFO, CSE_FSL_main.py:main():276]  > R 162, agg. final model, testing loss: 0.75, testing acc: 73.91% ( 7391/10000), training loss: 0.80, training acc: 71.85%
[21/11/24 01:24:29, INFO, CSE_FSL_main.py:main():276]  > R 163, agg. final model, testing loss: 0.74, testing acc: 74.44% ( 7444/10000), training loss: 0.78, training acc: 72.58%
[21/11/24 01:24:54, INFO, CSE_FSL_main.py:main():276]  > R 164, agg. final model, testing loss: 0.74, testing acc: 74.61% ( 7461/10000), training loss: 0.79, training acc: 72.22%
[21/11/24 01:25:20, INFO, CSE_FSL_main.py:main():276]  > R 165, agg. final model, testing loss: 0.75, testing acc: 74.12% ( 7412/10000), training loss: 0.80, training acc: 72.22%
[21/11/24 01:25:45, INFO, CSE_FSL_main.py:main():276]  > R 166, agg. final model, testing loss: 0.76, testing acc: 74.05% ( 7405/10000), training loss: 0.79, training acc: 72.32%
[21/11/24 01:26:10, INFO, CSE_FSL_main.py:main():276]  > R 167, agg. final model, testing loss: 0.74, testing acc: 74.27% ( 7427/10000), training loss: 0.78, training acc: 72.78%
[21/11/24 01:26:35, INFO, CSE_FSL_main.py:main():276]  > R 168, agg. final model, testing loss: 0.74, testing acc: 74.22% ( 7422/10000), training loss: 0.79, training acc: 72.43%
[21/11/24 01:27:01, INFO, CSE_FSL_main.py:main():276]  > R 169, agg. final model, testing loss: 0.74, testing acc: 74.74% ( 7474/10000), training loss: 0.77, training acc: 72.94%
[21/11/24 01:27:26, INFO, CSE_FSL_main.py:main():276]  > R 170, agg. final model, testing loss: 0.74, testing acc: 74.81% ( 7481/10000), training loss: 0.79, training acc: 72.55%
[21/11/24 01:27:51, INFO, CSE_FSL_main.py:main():276]  > R 171, agg. final model, testing loss: 0.74, testing acc: 74.68% ( 7468/10000), training loss: 0.79, training acc: 72.45%
[21/11/24 01:28:16, INFO, CSE_FSL_main.py:main():276]  > R 172, agg. final model, testing loss: 0.74, testing acc: 74.21% ( 7421/10000), training loss: 0.77, training acc: 73.03%
[21/11/24 01:28:42, INFO, CSE_FSL_main.py:main():276]  > R 173, agg. final model, testing loss: 0.73, testing acc: 74.88% ( 7488/10000), training loss: 0.78, training acc: 72.70%
[21/11/24 01:29:07, INFO, CSE_FSL_main.py:main():276]  > R 174, agg. final model, testing loss: 0.74, testing acc: 74.76% ( 7476/10000), training loss: 0.79, training acc: 72.36%
[21/11/24 01:29:32, INFO, CSE_FSL_main.py:main():276]  > R 175, agg. final model, testing loss: 0.74, testing acc: 74.05% ( 7405/10000), training loss: 0.78, training acc: 72.94%
[21/11/24 01:29:57, INFO, CSE_FSL_main.py:main():276]  > R 176, agg. final model, testing loss: 0.76, testing acc: 73.80% ( 7380/10000), training loss: 0.80, training acc: 72.27%
[21/11/24 01:30:23, INFO, CSE_FSL_main.py:main():276]  > R 177, agg. final model, testing loss: 0.74, testing acc: 74.70% ( 7470/10000), training loss: 0.77, training acc: 73.08%
[21/11/24 01:30:48, INFO, CSE_FSL_main.py:main():276]  > R 178, agg. final model, testing loss: 0.74, testing acc: 74.59% ( 7459/10000), training loss: 0.79, training acc: 72.53%
[21/11/24 01:31:13, INFO, CSE_FSL_main.py:main():276]  > R 179, agg. final model, testing loss: 0.73, testing acc: 74.46% ( 7446/10000), training loss: 0.77, training acc: 73.11%
[21/11/24 01:31:38, INFO, CSE_FSL_main.py:main():276]  > R 180, agg. final model, testing loss: 0.73, testing acc: 74.58% ( 7458/10000), training loss: 0.77, training acc: 73.08%
[21/11/24 01:32:04, INFO, CSE_FSL_main.py:main():276]  > R 181, agg. final model, testing loss: 0.72, testing acc: 75.29% ( 7529/10000), training loss: 0.76, training acc: 73.57%
[21/11/24 01:32:29, INFO, CSE_FSL_main.py:main():276]  > R 182, agg. final model, testing loss: 0.73, testing acc: 74.76% ( 7476/10000), training loss: 0.77, training acc: 73.03%
[21/11/24 01:32:54, INFO, CSE_FSL_main.py:main():276]  > R 183, agg. final model, testing loss: 0.73, testing acc: 74.63% ( 7463/10000), training loss: 0.77, training acc: 73.26%
[21/11/24 01:33:19, INFO, CSE_FSL_main.py:main():276]  > R 184, agg. final model, testing loss: 0.74, testing acc: 74.53% ( 7453/10000), training loss: 0.77, training acc: 73.26%
[21/11/24 01:33:45, INFO, CSE_FSL_main.py:main():276]  > R 185, agg. final model, testing loss: 0.72, testing acc: 75.35% ( 7535/10000), training loss: 0.76, training acc: 73.57%
[21/11/24 01:34:10, INFO, CSE_FSL_main.py:main():276]  > R 186, agg. final model, testing loss: 0.73, testing acc: 74.70% ( 7470/10000), training loss: 0.77, training acc: 73.08%
[21/11/24 01:34:35, INFO, CSE_FSL_main.py:main():276]  > R 187, agg. final model, testing loss: 0.74, testing acc: 74.65% ( 7465/10000), training loss: 0.77, training acc: 72.99%
[21/11/24 01:35:01, INFO, CSE_FSL_main.py:main():276]  > R 188, agg. final model, testing loss: 0.73, testing acc: 74.96% ( 7496/10000), training loss: 0.76, training acc: 73.57%
[21/11/24 01:35:26, INFO, CSE_FSL_main.py:main():276]  > R 189, agg. final model, testing loss: 0.73, testing acc: 74.83% ( 7483/10000), training loss: 0.76, training acc: 73.24%
[21/11/24 01:35:51, INFO, CSE_FSL_main.py:main():276]  > R 190, agg. final model, testing loss: 0.74, testing acc: 74.90% ( 7490/10000), training loss: 0.77, training acc: 73.21%
[21/11/24 01:36:16, INFO, CSE_FSL_main.py:main():276]  > R 191, agg. final model, testing loss: 0.73, testing acc: 74.70% ( 7470/10000), training loss: 0.76, training acc: 73.62%
[21/11/24 01:36:42, INFO, CSE_FSL_main.py:main():276]  > R 192, agg. final model, testing loss: 0.73, testing acc: 74.99% ( 7499/10000), training loss: 0.76, training acc: 73.42%
[21/11/24 01:37:07, INFO, CSE_FSL_main.py:main():276]  > R 193, agg. final model, testing loss: 0.73, testing acc: 74.99% ( 7499/10000), training loss: 0.77, training acc: 72.97%
[21/11/24 01:37:32, INFO, CSE_FSL_main.py:main():276]  > R 194, agg. final model, testing loss: 0.74, testing acc: 74.60% ( 7460/10000), training loss: 0.77, training acc: 73.25%
[21/11/24 01:37:57, INFO, CSE_FSL_main.py:main():276]  > R 195, agg. final model, testing loss: 0.72, testing acc: 75.02% ( 7502/10000), training loss: 0.76, training acc: 73.59%
[21/11/24 01:38:23, INFO, CSE_FSL_main.py:main():276]  > R 196, agg. final model, testing loss: 0.73, testing acc: 75.03% ( 7503/10000), training loss: 0.75, training acc: 73.84%
[21/11/24 01:38:48, INFO, CSE_FSL_main.py:main():276]  > R 197, agg. final model, testing loss: 0.73, testing acc: 75.03% ( 7503/10000), training loss: 0.75, training acc: 73.66%
[21/11/24 01:39:13, INFO, CSE_FSL_main.py:main():276]  > R 198, agg. final model, testing loss: 0.72, testing acc: 75.00% ( 7500/10000), training loss: 0.76, training acc: 73.62%
[21/11/24 01:39:38, INFO, CSE_FSL_main.py:main():276]  > R 199, agg. final model, testing loss: 0.75, testing acc: 74.40% ( 7440/10000), training loss: 0.78, training acc: 72.91%
[21/11/24 01:39:38, INFO, CSE_FSL_main.py:main():278] The total running time for all rounds is 5026.95 seconds
[21/11/24 01:39:38, INFO, CSE_FSL_main.py:main():288] [NOTICE] Saved results to '../saves/cifar-iid-K3U3E1BR5-200-241121-001549/results.json'.
[21/11/24 01:39:39, INFO, CSE_FSL_main.py:main():300] Testing accuracy: [0.1054, 0.2365, 0.2954, 0.3168, 0.3602, 0.3886, 0.402, 0.403, 0.4256, 0.4253, 0.4465, 0.4528, 0.4609, 0.4707, 0.474, 0.4883, 0.4869, 0.4997, 0.5032, 0.5127, 0.521, 0.5223, 0.5341, 0.5361, 0.5541, 0.5561, 0.5623, 0.5548, 0.5773, 0.5843, 0.5808, 0.5908, 0.5914, 0.6043, 0.6044, 0.6184, 0.6188, 0.6236, 0.6249, 0.6375, 0.6295, 0.6288, 0.641, 0.6398, 0.6451, 0.6425, 0.6533, 0.6567, 0.6536, 0.6574, 0.6583, 0.6673, 0.6589, 0.6613, 0.6696, 0.6687, 0.6785, 0.6791, 0.6772, 0.6664, 0.6769, 0.6698, 0.6798, 0.6879, 0.6863, 0.6897, 0.6922, 0.6878, 0.6904, 0.6987, 0.6922, 0.7073, 0.6965, 0.7, 0.7019, 0.7044, 0.703, 0.7042, 0.7086, 0.6995, 0.7061, 0.7099, 0.7085, 0.7125, 0.7064, 0.7119, 0.7071, 0.7131, 0.7139, 0.7119, 0.713, 0.7138, 0.7024, 0.7174, 0.7122, 0.7229, 0.7131, 0.7128, 0.7215, 0.7216, 0.7232, 0.722, 0.7224, 0.709, 0.7168, 0.7216, 0.7201, 0.7255, 0.7223, 0.7226, 0.7235, 0.7303, 0.7259, 0.729, 0.7253, 0.722, 0.7266, 0.7257, 0.7309, 0.7293, 0.7256, 0.7285, 0.7281, 0.7272, 0.7332, 0.7364, 0.7318, 0.7326, 0.7356, 0.7312, 0.7292, 0.7333, 0.7425, 0.7402, 0.7338, 0.734, 0.7334, 0.7306, 0.737, 0.7378, 0.7335, 0.7392, 0.7389, 0.7363, 0.7359, 0.7409, 0.7302, 0.7387, 0.7433, 0.7391, 0.7331, 0.7409, 0.7397, 0.7311, 0.73, 0.7431, 0.7412, 0.7397, 0.7469, 0.7363, 0.7425, 0.7453, 0.7391, 0.7444, 0.7461, 0.7412, 0.7405, 0.7427, 0.7422, 0.7474, 0.7481, 0.7468, 0.7421, 0.7488, 0.7476, 0.7405, 0.738, 0.747, 0.7459, 0.7446, 0.7458, 0.7529, 0.7476, 0.7463, 0.7453, 0.7535, 0.747, 0.7465, 0.7496, 0.7483, 0.749, 0.747, 0.7499, 0.7499, 0.746, 0.7502, 0.7503, 0.7503, 0.75, 0.744]
[21/11/24 01:39:39, INFO, CSE_FSL_main.py:main():301] Testing loss: [2.292274022404152, 1.9811131878744197, 1.8662525113624862, 1.8351518941830984, 1.7109592277792436, 1.6625499981868117, 1.6285276307335383, 1.6022683306585384, 1.561129452307013, 1.5568975617613974, 1.5199137413049046, 1.4886137443252756, 1.4711949387683143, 1.4576732855808885, 1.4458722027042243, 1.4134473770479612, 1.4034062880503981, 1.3770546053029313, 1.3742489271526095, 1.3458485799499704, 1.3348638603958902, 1.3282500671435007, 1.2914642834965187, 1.2858921198905269, 1.261449708214289, 1.247708387012723, 1.236900438236285, 1.247157970561257, 1.1919040815739692, 1.1826082649110239, 1.17670656457732, 1.1519563914854316, 1.1473434001584597, 1.1342327662661105, 1.1185346411753305, 1.089874042740351, 1.0904713152330132, 1.081688088706777, 1.0649738628653032, 1.053945005694522, 1.0548816715614706, 1.0518045085894911, 1.0376058107689967, 1.0326613527310045, 1.0256157449529142, 1.0203240551526034, 0.9972763846192179, 0.9934461312957957, 0.989151838459546, 0.9880060168761241, 0.9919973144048377, 0.9596000328848634, 0.9741770172420936, 0.9766557329817663, 0.9577463676657858, 0.9532782216615314, 0.9266471915607211, 0.9297189327734935, 0.9306935343561293, 0.9453422442267213, 0.9254556056819384, 0.9372819443292255, 0.9213173449793949, 0.8989946027345295, 0.8995022139971769, 0.8973581240146975, 0.8909667232368566, 0.8986666112006465, 0.8893957447402084, 0.8712708678426622, 0.8852708520768564, 0.8537780265264874, 0.8769771268096151, 0.8783830562724343, 0.8639973975435088, 0.8467746437350406, 0.8519712241390084, 0.8525401723535755, 0.8473091849797889, 0.8540576251247262, 0.8511875483054149, 0.8432764916480342, 0.8373492729814747, 0.826050233237351, 0.8340119689325743, 0.8361665719672094, 0.8439669888230819, 0.8252019972740849, 0.8355381526524508, 0.8283739565294, 0.829584149620201, 0.8248455660252632, 0.8536704461785811, 0.814017008377027, 0.8200403482099122, 0.8006946965108944, 0.8234887545621847, 0.8171601687805562, 0.8060356974601746, 0.7999362198612358, 0.7962597012519836, 0.8032098638860485, 0.7864429098141344, 0.824803706965869, 0.809422142143491, 0.8056097800218607, 0.796081438849244, 0.7881921031807042, 0.7935156527953812, 0.7922443785244906, 0.7926714171337176, 0.7823819084258019, 0.7957330911974364, 0.7801937989041775, 0.7947002302242231, 0.7994567027574853, 0.7784820100929164, 0.7797443082060995, 0.7779348635975318, 0.7809045903290375, 0.7849213895918448, 0.7717923144750958, 0.7796519572221781, 0.7818832073030593, 0.7665770944160751, 0.7591429130186008, 0.7789140969892091, 0.7690594796138474, 0.7696274903756154, 0.7705227257330206, 0.7792384118973454, 0.7763513673709918, 0.7547787571255165, 0.7623166819162006, 0.77516500783872, 0.7707211790205557, 0.7595275067075898, 0.7667618250545067, 0.7568534725829016, 0.749342569444753, 0.7539451605157007, 0.7519551055340827, 0.7577937479260601, 0.7580496012410031, 0.758051716828648, 0.7524915028222, 0.7662511747094649, 0.7454097584078584, 0.7399293546435199, 0.7526749836493142, 0.7637866610967661, 0.7588292469706717, 0.7503605971607981, 0.7598912655552731, 0.7681414439708372, 0.7524006042299392, 0.749182638865483, 0.7534609180462511, 0.7397553943380525, 0.7533587843556947, 0.7483668319786652, 0.7467551472820814, 0.7487562268595153, 0.7392362710795825, 0.7390101646320729, 0.7476030082642278, 0.7558896617044376, 0.7433588723593121, 0.7397385839420029, 0.7387570338913158, 0.7429325701315191, 0.736934783715236, 0.7403463174270678, 0.7312644373012495, 0.7363906136796444, 0.7374817955343029, 0.7587411686589446, 0.7361761241019527, 0.7420520186424255, 0.7317065241970594, 0.7342965402935124, 0.7197513308706163, 0.7280831574639187, 0.7316935466060156, 0.7367843596995631, 0.7234878924828542, 0.7285870162746574, 0.738073271663883, 0.7311118237579926, 0.7273717360405982, 0.7356520902506912, 0.7332150011877471, 0.7295837975755523, 0.7345060645779476, 0.7382860545870624, 0.7221480366549914, 0.7319650861281383, 0.7266516904287701, 0.7216058482852163, 0.7492057756532596]
[21/11/24 01:39:39, INFO, CSE_FSL_main.py:main():302] Training accuracy: [0.10714428577143086, 0.21604864194567783, 0.26345053802152085, 0.2763110524420977, 0.31067242689707586, 0.343873754950198, 0.35497419896795873, 0.3500540021600864, 0.37563502540101606, 0.3833153326133045, 0.3875955038201528, 0.40341613664546583, 0.4099163966558662, 0.41955678227129084, 0.4160366414656586, 0.4360374414976599, 0.438117524700988, 0.44929797191887677, 0.4499179967198688, 0.4643385735429417, 0.4659586383455338, 0.47105884235369416, 0.48171926877075083, 0.4877395095803832, 0.4951598063922557, 0.5018400736029441, 0.5053602144085764, 0.499259970398816, 0.5235009400376015, 0.5280211208448338, 0.5288411536461458, 0.5351414056562263, 0.5345013800552022, 0.5420616824672987, 0.5486419456778271, 0.5598223928957158, 0.5579823192927718, 0.5644825793031721, 0.5690427617104684, 0.5766830673226929, 0.5803632145285812, 0.5792631705268211, 0.5868434737389495, 0.5860434417376695, 0.5845633825353014, 0.5958838353534142, 0.5959638385535422, 0.6046441857674307, 0.5991239649585983, 0.6045241809672387, 0.6010240409616384, 0.610084403376135, 0.6107844313772551, 0.6027241089643586, 0.6219448777951118, 0.6196447857914317, 0.6226849073962959, 0.6327053082123285, 0.6210448417936717, 0.6189647585903436, 0.625145005800232, 0.6211848473938958, 0.6337253490139606, 0.641065642625705, 0.6428057122284891, 0.6447057882315292, 0.6495259810392415, 0.640605624224969, 0.6457858314332573, 0.6502860114404576, 0.6476659066362654, 0.6631865274610984, 0.6511660466418657, 0.641925677027081, 0.6471458858354334, 0.6605264210568422, 0.6607064282571303, 0.6628465138605544, 0.6623264930597224, 0.6630665226609065, 0.6657866314652586, 0.6651666066642665, 0.6690667626705068, 0.673246929877195, 0.6679067162686507, 0.6695467818712748, 0.6649465978639145, 0.6745469818792752, 0.6655066202648106, 0.671766870674827, 0.672546901876075, 0.6745469818792752, 0.6666866674666987, 0.6802072082883316, 0.6787271490859634, 0.6837273490939637, 0.6763670546821873, 0.6803872154886196, 0.6903076123044922, 0.686967478699148, 0.6903676147045882, 0.687447497899916, 0.6908676347053883, 0.6804072162886515, 0.6916076643065723, 0.6855274210968438, 0.688147525901036, 0.6897075883035322, 0.6886475459018361, 0.6940477619104765, 0.6897275891035641, 0.6982879315172607, 0.6949477979119165, 0.6972678907156287, 0.6982079283171326, 0.6907276291051642, 0.7009880395215808, 0.6983479339173567, 0.702748109924397, 0.6960078403136125, 0.6988879555182207, 0.7022880915236609, 0.7049881995279811, 0.7072482899315973, 0.7070482819312772, 0.7106284251370055, 0.7056082243289732, 0.7019680787231489, 0.7054682187287491, 0.7071082843313733, 0.7014480579223169, 0.7088283531341254, 0.7142485699427977, 0.7082083283331333, 0.7121884875395016, 0.7089683587343494, 0.7101284051362055, 0.7079283171326853, 0.7122884915396616, 0.7174286971478859, 0.7112684507380295, 0.719588783551342, 0.7148085923436938, 0.7154086163446538, 0.7157086283451338, 0.7146485859434377, 0.7098083923356935, 0.7178287131485259, 0.71866874674987, 0.7228489139565583, 0.7173486939477579, 0.718428737149486, 0.7214088563542542, 0.7169886795471819, 0.7166086643465739, 0.7142885715428617, 0.7185287411496459, 0.7193487739509581, 0.7227489099563983, 0.7219088763550542, 0.718808752350094, 0.7242089683587344, 0.718488739549582, 0.7258490339613585, 0.7222488899555982, 0.7222088883555342, 0.7232289291571663, 0.7278291131645266, 0.7243089723588944, 0.7294291771670867, 0.7255290211608464, 0.7245089803592144, 0.7303492139685588, 0.7270090803632145, 0.7236489459578384, 0.7294091763670547, 0.7227289091563662, 0.7308092323692947, 0.7253090123604944, 0.7311092443697748, 0.7307892315692628, 0.735669426777071, 0.7303092123684948, 0.7326293051722069, 0.7326293051722069, 0.7357294291771671, 0.7308292331693268, 0.7298891955678227, 0.735709428377135, 0.7323692947717909, 0.7320692827713109, 0.7362494499779991, 0.734229369174767, 0.7297091883675347, 0.7325093003720149, 0.7358894355774231, 0.7384095363814552, 0.7365894635785432, 0.7362094483779351, 0.7291491659666387]
[21/11/24 01:39:39, INFO, CSE_FSL_main.py:main():303] Training loss: [2.293731061556867, 2.043555075279022, 1.9349685503932963, 1.9183085777680686, 1.828136759253252, 1.769731459120151, 1.7479721577719574, 1.7360734942608511, 1.7025310419897997, 1.6850845146421864, 1.6587875529403298, 1.6247702739924268, 1.6087653667265525, 1.5948184030959929, 1.587292234102885, 1.5492988730811588, 1.5439032276774787, 1.5145939464180826, 1.5129967912766162, 1.4822827984055187, 1.478808709076646, 1.4577347173642263, 1.4321971811714367, 1.4243941922830867, 1.3969212688562525, 1.381987730662028, 1.3806674422805243, 1.3827000592501109, 1.3345716142169088, 1.3165847560528277, 1.3069191861698646, 1.298640026694339, 1.3028273706824423, 1.2724941077123162, 1.2607815920851613, 1.2338009249163038, 1.2453700029516341, 1.2306461070330088, 1.206143614900021, 1.1886891948661125, 1.1754355567102215, 1.1783720462680167, 1.1662845664655284, 1.165317920783094, 1.173722565022437, 1.1443600537819414, 1.13057976490972, 1.1213624836834333, 1.1291901548096848, 1.1226904883639504, 1.1290270059769998, 1.0991401510080916, 1.1092245343683937, 1.1347912945820176, 1.0769921544247305, 1.0754795015313243, 1.0716435898654637, 1.0437896595959748, 1.075150239861952, 1.0773254993914345, 1.057258359348501, 1.066728924673629, 1.0423680792631387, 1.0196511734836278, 1.025609935967977, 1.0152698697631293, 1.0038806336526653, 1.0203741138218014, 1.0060943776111264, 0.9951263550886974, 1.0072216071548656, 0.9693836333187482, 0.993441729600193, 1.0050030688899771, 1.0007063271738494, 0.9679997624028427, 0.9700576110953897, 0.9643006336901327, 0.9660284654178085, 0.9611253524554595, 0.9611897838631356, 0.9523744257048493, 0.9447385906869825, 0.930028679716678, 0.9410808357876979, 0.9366906923798811, 0.9547809761292455, 0.9297736077818252, 0.9501423517256292, 0.9369913618679871, 0.929272544444669, 0.9244267920804691, 0.9437861395549532, 0.9101600141925666, 0.9160879789721268, 0.8983403004459449, 0.9228125226709982, 0.9108948646155932, 0.8869136734166522, 0.8947431712053507, 0.884505045626303, 0.8913696154989965, 0.8807238194778675, 0.9118329263825453, 0.8901208445012722, 0.8924929942490187, 0.8938347874706938, 0.884560957513086, 0.8822182862813236, 0.8780157579720476, 0.8822363034156139, 0.8653074419528777, 0.8736262036340534, 0.8614186544454735, 0.8678134236930284, 0.8821138645553104, 0.8508145718174126, 0.8637788373095389, 0.8450541657042564, 0.8666869571797418, 0.8553451334550484, 0.8483283885259362, 0.8465057989113204, 0.8420577665018368, 0.8379242476312866, 0.8243836937969877, 0.8424618881167346, 0.8512558931006123, 0.8375899937316662, 0.8356290732631246, 0.8460404633262382, 0.8357169073046619, 0.8179017805871163, 0.8348705756451944, 0.8283347237201137, 0.8288292593628396, 0.8256312243204383, 0.8358877289082864, 0.8281063493578186, 0.8036472248363737, 0.8242464073135046, 0.8071027316209924, 0.8118956515200568, 0.8176296062141885, 0.8135330953064159, 0.8136552731499417, 0.8224110376592204, 0.8039068661573279, 0.7982444379469213, 0.7940474839610908, 0.8080728446860956, 0.8080178004791415, 0.7940609665924053, 0.8129078254444908, 0.8090208966010096, 0.8160125092999019, 0.8092295990038767, 0.7997018776777136, 0.7904305260903356, 0.7933337066616417, 0.8007367697684212, 0.7926346242579492, 0.8020891557819667, 0.7800314951943987, 0.7864092453442154, 0.7957158481498408, 0.792743204659178, 0.7784572609204979, 0.7911035444293617, 0.7737300536256406, 0.785427169869571, 0.7859540091822772, 0.7725126740283336, 0.7813114796886007, 0.7871559372991702, 0.7768033799020996, 0.7972550082752723, 0.7717260870011405, 0.7851774294412773, 0.7700729747764937, 0.7677061184671999, 0.7562171483161189, 0.7726877789764307, 0.767089538143488, 0.7685837079853806, 0.7581073344512144, 0.766057942204803, 0.7692375574403136, 0.7574991923555466, 0.7644685082156543, 0.7688508469033181, 0.7622845049274484, 0.7576763827837151, 0.7705500435283166, 0.7698425312381968, 0.755341278839354, 0.749861326608949, 0.7531054142777246, 0.7560931717166464, 0.7785351815569492]
