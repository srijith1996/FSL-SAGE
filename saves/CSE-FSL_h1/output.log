[24/11/24 13:36:57, INFO, CSE_FSL_main.py:<module>():315] Using GPU: True
[24/11/24 13:36:59, INFO, CSE_FSL_main.py:main():107] Aggregation Factor: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]
[24/11/24 13:36:59, INFO, CSE_FSL_main.py:main():112] Random seed: 200
[24/11/24 13:36:59, INFO, CSE_FSL_main.py:main():113] Alignment interval (l): 10
[24/11/24 13:36:59, INFO, CSE_FSL_main.py:main():114] Batch Round (h): 1
[24/11/24 13:37:25, INFO, CSE_FSL_main.py:main():269]  > R  0, agg. final model, testing loss: 2.22, testing acc: 17.22% ( 1722/10000), training loss: 2.23, training acc: 15.26%
[24/11/24 13:37:51, INFO, CSE_FSL_main.py:main():269]  > R  1, agg. final model, testing loss: 1.89, testing acc: 29.53% ( 2953/10000), training loss: 1.97, training acc: 26.04%
[24/11/24 13:38:16, INFO, CSE_FSL_main.py:main():269]  > R  2, agg. final model, testing loss: 1.77, testing acc: 34.44% ( 3444/10000), training loss: 1.87, training acc: 30.01%
[24/11/24 13:38:42, INFO, CSE_FSL_main.py:main():269]  > R  3, agg. final model, testing loss: 1.72, testing acc: 36.32% ( 3632/10000), training loss: 1.83, training acc: 31.34%
[24/11/24 13:39:08, INFO, CSE_FSL_main.py:main():269]  > R  4, agg. final model, testing loss: 1.64, testing acc: 39.31% ( 3931/10000), training loss: 1.77, training acc: 33.80%
[24/11/24 13:39:33, INFO, CSE_FSL_main.py:main():269]  > R  5, agg. final model, testing loss: 1.60, testing acc: 40.42% ( 4042/10000), training loss: 1.71, training acc: 36.56%
[24/11/24 13:39:59, INFO, CSE_FSL_main.py:main():269]  > R  6, agg. final model, testing loss: 1.56, testing acc: 41.84% ( 4184/10000), training loss: 1.68, training acc: 38.22%
[24/11/24 13:40:24, INFO, CSE_FSL_main.py:main():269]  > R  7, agg. final model, testing loss: 1.52, testing acc: 44.56% ( 4456/10000), training loss: 1.64, training acc: 39.77%
[24/11/24 13:40:50, INFO, CSE_FSL_main.py:main():269]  > R  8, agg. final model, testing loss: 1.51, testing acc: 44.47% ( 4447/10000), training loss: 1.63, training acc: 39.73%
[24/11/24 13:41:15, INFO, CSE_FSL_main.py:main():269]  > R  9, agg. final model, testing loss: 1.46, testing acc: 46.71% ( 4671/10000), training loss: 1.59, training acc: 41.59%
[24/11/24 13:41:41, INFO, CSE_FSL_main.py:main():269]  > R 10, agg. final model, testing loss: 1.44, testing acc: 47.69% ( 4769/10000), training loss: 1.57, training acc: 42.38%
[24/11/24 13:42:07, INFO, CSE_FSL_main.py:main():269]  > R 11, agg. final model, testing loss: 1.42, testing acc: 48.32% ( 4832/10000), training loss: 1.54, training acc: 43.32%
[24/11/24 13:42:32, INFO, CSE_FSL_main.py:main():269]  > R 12, agg. final model, testing loss: 1.40, testing acc: 49.06% ( 4906/10000), training loss: 1.53, training acc: 43.84%
[24/11/24 13:42:58, INFO, CSE_FSL_main.py:main():269]  > R 13, agg. final model, testing loss: 1.39, testing acc: 49.43% ( 4943/10000), training loss: 1.52, training acc: 44.54%
[24/11/24 13:43:23, INFO, CSE_FSL_main.py:main():269]  > R 14, agg. final model, testing loss: 1.37, testing acc: 50.46% ( 5046/10000), training loss: 1.50, training acc: 45.77%
[24/11/24 13:43:49, INFO, CSE_FSL_main.py:main():269]  > R 15, agg. final model, testing loss: 1.33, testing acc: 52.67% ( 5267/10000), training loss: 1.45, training acc: 47.34%
[24/11/24 13:44:15, INFO, CSE_FSL_main.py:main():269]  > R 16, agg. final model, testing loss: 1.32, testing acc: 52.24% ( 5224/10000), training loss: 1.44, training acc: 47.98%
[24/11/24 13:44:40, INFO, CSE_FSL_main.py:main():269]  > R 17, agg. final model, testing loss: 1.30, testing acc: 53.02% ( 5302/10000), training loss: 1.42, training acc: 48.88%
[24/11/24 13:45:06, INFO, CSE_FSL_main.py:main():269]  > R 18, agg. final model, testing loss: 1.29, testing acc: 53.73% ( 5373/10000), training loss: 1.43, training acc: 48.43%
[24/11/24 13:45:32, INFO, CSE_FSL_main.py:main():269]  > R 19, agg. final model, testing loss: 1.26, testing acc: 55.10% ( 5510/10000), training loss: 1.39, training acc: 49.81%
[24/11/24 13:45:57, INFO, CSE_FSL_main.py:main():269]  > R 20, agg. final model, testing loss: 1.26, testing acc: 55.08% ( 5508/10000), training loss: 1.39, training acc: 49.31%
[24/11/24 13:46:23, INFO, CSE_FSL_main.py:main():269]  > R 21, agg. final model, testing loss: 1.24, testing acc: 55.95% ( 5595/10000), training loss: 1.36, training acc: 50.95%
[24/11/24 13:46:48, INFO, CSE_FSL_main.py:main():269]  > R 22, agg. final model, testing loss: 1.21, testing acc: 56.82% ( 5682/10000), training loss: 1.34, training acc: 51.71%
[24/11/24 13:47:14, INFO, CSE_FSL_main.py:main():269]  > R 23, agg. final model, testing loss: 1.19, testing acc: 57.43% ( 5743/10000), training loss: 1.32, training acc: 52.60%
[24/11/24 13:47:40, INFO, CSE_FSL_main.py:main():269]  > R 24, agg. final model, testing loss: 1.19, testing acc: 57.73% ( 5773/10000), training loss: 1.31, training acc: 52.57%
[24/11/24 13:48:05, INFO, CSE_FSL_main.py:main():269]  > R 25, agg. final model, testing loss: 1.17, testing acc: 58.44% ( 5844/10000), training loss: 1.29, training acc: 53.85%
[24/11/24 13:48:31, INFO, CSE_FSL_main.py:main():269]  > R 26, agg. final model, testing loss: 1.16, testing acc: 59.37% ( 5937/10000), training loss: 1.28, training acc: 54.32%
[24/11/24 13:48:56, INFO, CSE_FSL_main.py:main():269]  > R 27, agg. final model, testing loss: 1.13, testing acc: 60.24% ( 6024/10000), training loss: 1.26, training acc: 54.59%
[24/11/24 13:49:22, INFO, CSE_FSL_main.py:main():269]  > R 28, agg. final model, testing loss: 1.10, testing acc: 61.60% ( 6160/10000), training loss: 1.22, training acc: 56.18%
[24/11/24 13:49:47, INFO, CSE_FSL_main.py:main():269]  > R 29, agg. final model, testing loss: 1.10, testing acc: 61.63% ( 6163/10000), training loss: 1.22, training acc: 56.57%
[24/11/24 13:50:13, INFO, CSE_FSL_main.py:main():269]  > R 30, agg. final model, testing loss: 1.09, testing acc: 61.59% ( 6159/10000), training loss: 1.21, training acc: 56.74%
[24/11/24 13:50:39, INFO, CSE_FSL_main.py:main():269]  > R 31, agg. final model, testing loss: 1.06, testing acc: 62.72% ( 6272/10000), training loss: 1.19, training acc: 57.52%
[24/11/24 13:51:04, INFO, CSE_FSL_main.py:main():269]  > R 32, agg. final model, testing loss: 1.05, testing acc: 62.65% ( 6265/10000), training loss: 1.17, training acc: 58.56%
[24/11/24 13:51:30, INFO, CSE_FSL_main.py:main():269]  > R 33, agg. final model, testing loss: 1.04, testing acc: 63.52% ( 6352/10000), training loss: 1.16, training acc: 58.83%
[24/11/24 13:51:55, INFO, CSE_FSL_main.py:main():269]  > R 34, agg. final model, testing loss: 1.02, testing acc: 63.89% ( 6389/10000), training loss: 1.14, training acc: 59.42%
[24/11/24 13:52:21, INFO, CSE_FSL_main.py:main():269]  > R 35, agg. final model, testing loss: 1.00, testing acc: 65.07% ( 6507/10000), training loss: 1.12, training acc: 60.01%
[24/11/24 13:52:47, INFO, CSE_FSL_main.py:main():269]  > R 36, agg. final model, testing loss: 0.99, testing acc: 65.15% ( 6515/10000), training loss: 1.13, training acc: 59.75%
[24/11/24 13:53:12, INFO, CSE_FSL_main.py:main():269]  > R 37, agg. final model, testing loss: 0.98, testing acc: 65.72% ( 6572/10000), training loss: 1.10, training acc: 61.10%
[24/11/24 13:53:38, INFO, CSE_FSL_main.py:main():269]  > R 38, agg. final model, testing loss: 0.97, testing acc: 65.71% ( 6571/10000), training loss: 1.09, training acc: 61.39%
[24/11/24 13:54:03, INFO, CSE_FSL_main.py:main():269]  > R 39, agg. final model, testing loss: 0.95, testing acc: 66.75% ( 6675/10000), training loss: 1.07, training acc: 61.97%
[24/11/24 13:54:29, INFO, CSE_FSL_main.py:main():269]  > R 40, agg. final model, testing loss: 0.95, testing acc: 66.47% ( 6647/10000), training loss: 1.06, training acc: 62.63%
[24/11/24 13:54:55, INFO, CSE_FSL_main.py:main():269]  > R 41, agg. final model, testing loss: 0.95, testing acc: 66.37% ( 6637/10000), training loss: 1.05, training acc: 62.77%
[24/11/24 13:55:20, INFO, CSE_FSL_main.py:main():269]  > R 42, agg. final model, testing loss: 0.95, testing acc: 66.29% ( 6629/10000), training loss: 1.05, training acc: 62.91%
[24/11/24 13:55:46, INFO, CSE_FSL_main.py:main():269]  > R 43, agg. final model, testing loss: 0.93, testing acc: 67.50% ( 6750/10000), training loss: 1.05, training acc: 62.81%
[24/11/24 13:56:11, INFO, CSE_FSL_main.py:main():269]  > R 44, agg. final model, testing loss: 0.92, testing acc: 67.99% ( 6799/10000), training loss: 1.03, training acc: 63.42%
[24/11/24 13:56:37, INFO, CSE_FSL_main.py:main():269]  > R 45, agg. final model, testing loss: 0.92, testing acc: 67.91% ( 6791/10000), training loss: 1.01, training acc: 64.28%
[24/11/24 13:57:03, INFO, CSE_FSL_main.py:main():269]  > R 46, agg. final model, testing loss: 0.92, testing acc: 68.03% ( 6803/10000), training loss: 1.02, training acc: 64.09%
[24/11/24 13:57:28, INFO, CSE_FSL_main.py:main():269]  > R 47, agg. final model, testing loss: 0.92, testing acc: 68.09% ( 6809/10000), training loss: 1.01, training acc: 64.53%
[24/11/24 13:57:54, INFO, CSE_FSL_main.py:main():269]  > R 48, agg. final model, testing loss: 0.89, testing acc: 69.02% ( 6902/10000), training loss: 0.99, training acc: 65.00%
[24/11/24 13:58:19, INFO, CSE_FSL_main.py:main():269]  > R 49, agg. final model, testing loss: 0.89, testing acc: 68.90% ( 6890/10000), training loss: 0.98, training acc: 65.31%
[24/11/24 13:58:45, INFO, CSE_FSL_main.py:main():269]  > R 50, agg. final model, testing loss: 0.90, testing acc: 69.12% ( 6912/10000), training loss: 1.00, training acc: 64.53%
[24/11/24 13:59:11, INFO, CSE_FSL_main.py:main():269]  > R 51, agg. final model, testing loss: 0.87, testing acc: 69.58% ( 6958/10000), training loss: 0.97, training acc: 65.54%
[24/11/24 13:59:36, INFO, CSE_FSL_main.py:main():269]  > R 52, agg. final model, testing loss: 0.88, testing acc: 69.35% ( 6935/10000), training loss: 0.98, training acc: 65.71%
[24/11/24 14:00:02, INFO, CSE_FSL_main.py:main():269]  > R 53, agg. final model, testing loss: 0.87, testing acc: 70.26% ( 7026/10000), training loss: 0.97, training acc: 65.85%
[24/11/24 14:00:27, INFO, CSE_FSL_main.py:main():269]  > R 54, agg. final model, testing loss: 0.87, testing acc: 70.41% ( 7041/10000), training loss: 0.95, training acc: 66.57%
[24/11/24 14:00:53, INFO, CSE_FSL_main.py:main():269]  > R 55, agg. final model, testing loss: 0.86, testing acc: 70.19% ( 7019/10000), training loss: 0.94, training acc: 66.85%
[24/11/24 14:01:18, INFO, CSE_FSL_main.py:main():269]  > R 56, agg. final model, testing loss: 0.85, testing acc: 70.48% ( 7048/10000), training loss: 0.94, training acc: 67.05%
[24/11/24 14:01:44, INFO, CSE_FSL_main.py:main():269]  > R 57, agg. final model, testing loss: 0.86, testing acc: 70.32% ( 7032/10000), training loss: 0.93, training acc: 67.03%
[24/11/24 14:02:10, INFO, CSE_FSL_main.py:main():269]  > R 58, agg. final model, testing loss: 0.83, testing acc: 70.99% ( 7099/10000), training loss: 0.92, training acc: 67.59%
[24/11/24 14:02:35, INFO, CSE_FSL_main.py:main():269]  > R 59, agg. final model, testing loss: 0.86, testing acc: 69.75% ( 6975/10000), training loss: 0.96, training acc: 66.05%
[24/11/24 14:03:01, INFO, CSE_FSL_main.py:main():269]  > R 60, agg. final model, testing loss: 0.84, testing acc: 71.11% ( 7111/10000), training loss: 0.93, training acc: 67.04%
[24/11/24 14:03:26, INFO, CSE_FSL_main.py:main():269]  > R 61, agg. final model, testing loss: 0.83, testing acc: 71.28% ( 7128/10000), training loss: 0.91, training acc: 67.57%
[24/11/24 14:03:52, INFO, CSE_FSL_main.py:main():269]  > R 62, agg. final model, testing loss: 0.84, testing acc: 70.79% ( 7079/10000), training loss: 0.91, training acc: 68.11%
[24/11/24 14:04:17, INFO, CSE_FSL_main.py:main():269]  > R 63, agg. final model, testing loss: 0.82, testing acc: 71.92% ( 7192/10000), training loss: 0.89, training acc: 68.55%
[24/11/24 14:04:43, INFO, CSE_FSL_main.py:main():269]  > R 64, agg. final model, testing loss: 0.82, testing acc: 71.32% ( 7132/10000), training loss: 0.91, training acc: 68.38%
[24/11/24 14:05:08, INFO, CSE_FSL_main.py:main():269]  > R 65, agg. final model, testing loss: 0.81, testing acc: 71.93% ( 7193/10000), training loss: 0.89, training acc: 68.80%
[24/11/24 14:05:34, INFO, CSE_FSL_main.py:main():269]  > R 66, agg. final model, testing loss: 0.82, testing acc: 71.67% ( 7167/10000), training loss: 0.89, training acc: 68.88%
[24/11/24 14:05:59, INFO, CSE_FSL_main.py:main():269]  > R 67, agg. final model, testing loss: 0.81, testing acc: 71.95% ( 7195/10000), training loss: 0.89, training acc: 68.63%
[24/11/24 14:06:25, INFO, CSE_FSL_main.py:main():269]  > R 68, agg. final model, testing loss: 0.81, testing acc: 71.84% ( 7184/10000), training loss: 0.88, training acc: 68.75%
[24/11/24 14:06:50, INFO, CSE_FSL_main.py:main():269]  > R 69, agg. final model, testing loss: 0.80, testing acc: 72.16% ( 7216/10000), training loss: 0.86, training acc: 69.51%
[24/11/24 14:07:16, INFO, CSE_FSL_main.py:main():269]  > R 70, agg. final model, testing loss: 0.79, testing acc: 72.58% ( 7258/10000), training loss: 0.87, training acc: 69.68%
[24/11/24 14:07:41, INFO, CSE_FSL_main.py:main():269]  > R 71, agg. final model, testing loss: 0.80, testing acc: 72.07% ( 7207/10000), training loss: 0.86, training acc: 70.00%
[24/11/24 14:08:07, INFO, CSE_FSL_main.py:main():269]  > R 72, agg. final model, testing loss: 0.81, testing acc: 72.36% ( 7236/10000), training loss: 0.87, training acc: 69.36%
[24/11/24 14:08:32, INFO, CSE_FSL_main.py:main():269]  > R 73, agg. final model, testing loss: 0.79, testing acc: 73.33% ( 7333/10000), training loss: 0.86, training acc: 69.41%
[24/11/24 14:08:58, INFO, CSE_FSL_main.py:main():269]  > R 74, agg. final model, testing loss: 0.79, testing acc: 72.59% ( 7259/10000), training loss: 0.86, training acc: 69.73%
[24/11/24 14:09:23, INFO, CSE_FSL_main.py:main():269]  > R 75, agg. final model, testing loss: 0.78, testing acc: 72.50% ( 7250/10000), training loss: 0.84, training acc: 70.52%
[24/11/24 14:09:49, INFO, CSE_FSL_main.py:main():269]  > R 76, agg. final model, testing loss: 0.77, testing acc: 73.35% ( 7335/10000), training loss: 0.83, training acc: 70.78%
[24/11/24 14:10:15, INFO, CSE_FSL_main.py:main():269]  > R 77, agg. final model, testing loss: 0.80, testing acc: 72.14% ( 7214/10000), training loss: 0.85, training acc: 70.25%
[24/11/24 14:10:40, INFO, CSE_FSL_main.py:main():269]  > R 78, agg. final model, testing loss: 0.77, testing acc: 73.15% ( 7315/10000), training loss: 0.83, training acc: 70.86%
[24/11/24 14:11:06, INFO, CSE_FSL_main.py:main():269]  > R 79, agg. final model, testing loss: 0.77, testing acc: 73.05% ( 7305/10000), training loss: 0.83, training acc: 70.80%
[24/11/24 14:11:31, INFO, CSE_FSL_main.py:main():269]  > R 80, agg. final model, testing loss: 0.78, testing acc: 73.14% ( 7314/10000), training loss: 0.83, training acc: 70.92%
[24/11/24 14:11:57, INFO, CSE_FSL_main.py:main():269]  > R 81, agg. final model, testing loss: 0.77, testing acc: 73.48% ( 7348/10000), training loss: 0.83, training acc: 70.98%
[24/11/24 14:12:23, INFO, CSE_FSL_main.py:main():269]  > R 82, agg. final model, testing loss: 0.77, testing acc: 73.66% ( 7366/10000), training loss: 0.82, training acc: 71.14%
[24/11/24 14:12:48, INFO, CSE_FSL_main.py:main():269]  > R 83, agg. final model, testing loss: 0.76, testing acc: 73.58% ( 7358/10000), training loss: 0.80, training acc: 71.74%
[24/11/24 14:13:14, INFO, CSE_FSL_main.py:main():269]  > R 84, agg. final model, testing loss: 0.77, testing acc: 73.42% ( 7342/10000), training loss: 0.81, training acc: 71.34%
[24/11/24 14:13:39, INFO, CSE_FSL_main.py:main():269]  > R 85, agg. final model, testing loss: 0.77, testing acc: 73.29% ( 7329/10000), training loss: 0.81, training acc: 71.61%
[24/11/24 14:14:05, INFO, CSE_FSL_main.py:main():269]  > R 86, agg. final model, testing loss: 0.77, testing acc: 73.48% ( 7348/10000), training loss: 0.82, training acc: 71.52%
[24/11/24 14:14:30, INFO, CSE_FSL_main.py:main():269]  > R 87, agg. final model, testing loss: 0.75, testing acc: 74.19% ( 7419/10000), training loss: 0.80, training acc: 71.67%
[24/11/24 14:14:56, INFO, CSE_FSL_main.py:main():269]  > R 88, agg. final model, testing loss: 0.77, testing acc: 72.96% ( 7296/10000), training loss: 0.82, training acc: 71.45%
[24/11/24 14:15:21, INFO, CSE_FSL_main.py:main():269]  > R 89, agg. final model, testing loss: 0.76, testing acc: 73.84% ( 7384/10000), training loss: 0.81, training acc: 71.53%
[24/11/24 14:15:47, INFO, CSE_FSL_main.py:main():269]  > R 90, agg. final model, testing loss: 0.76, testing acc: 74.10% ( 7410/10000), training loss: 0.79, training acc: 72.18%
[24/11/24 14:16:12, INFO, CSE_FSL_main.py:main():269]  > R 91, agg. final model, testing loss: 0.76, testing acc: 73.87% ( 7387/10000), training loss: 0.80, training acc: 72.07%
[24/11/24 14:16:38, INFO, CSE_FSL_main.py:main():269]  > R 92, agg. final model, testing loss: 0.76, testing acc: 73.32% ( 7332/10000), training loss: 0.79, training acc: 72.33%
[24/11/24 14:17:03, INFO, CSE_FSL_main.py:main():269]  > R 93, agg. final model, testing loss: 0.77, testing acc: 73.70% ( 7370/10000), training loss: 0.80, training acc: 71.83%
[24/11/24 14:17:29, INFO, CSE_FSL_main.py:main():269]  > R 94, agg. final model, testing loss: 0.76, testing acc: 73.58% ( 7358/10000), training loss: 0.79, training acc: 72.38%
[24/11/24 14:17:55, INFO, CSE_FSL_main.py:main():269]  > R 95, agg. final model, testing loss: 0.74, testing acc: 74.77% ( 7477/10000), training loss: 0.77, training acc: 72.93%
[24/11/24 14:18:20, INFO, CSE_FSL_main.py:main():269]  > R 96, agg. final model, testing loss: 0.74, testing acc: 74.20% ( 7420/10000), training loss: 0.77, training acc: 72.95%
[24/11/24 14:18:46, INFO, CSE_FSL_main.py:main():269]  > R 97, agg. final model, testing loss: 0.74, testing acc: 74.30% ( 7430/10000), training loss: 0.78, training acc: 72.61%
[24/11/24 14:19:12, INFO, CSE_FSL_main.py:main():269]  > R 98, agg. final model, testing loss: 0.75, testing acc: 74.08% ( 7408/10000), training loss: 0.76, training acc: 73.36%
[24/11/24 14:19:37, INFO, CSE_FSL_main.py:main():269]  > R 99, agg. final model, testing loss: 0.74, testing acc: 73.86% ( 7386/10000), training loss: 0.78, training acc: 72.74%
[24/11/24 14:20:03, INFO, CSE_FSL_main.py:main():269]  > R 100, agg. final model, testing loss: 0.74, testing acc: 74.77% ( 7477/10000), training loss: 0.76, training acc: 73.22%
[24/11/24 14:20:28, INFO, CSE_FSL_main.py:main():269]  > R 101, agg. final model, testing loss: 0.74, testing acc: 74.11% ( 7411/10000), training loss: 0.76, training acc: 73.06%
[24/11/24 14:20:54, INFO, CSE_FSL_main.py:main():269]  > R 102, agg. final model, testing loss: 0.74, testing acc: 74.42% ( 7442/10000), training loss: 0.76, training acc: 73.09%
[24/11/24 14:21:19, INFO, CSE_FSL_main.py:main():269]  > R 103, agg. final model, testing loss: 0.75, testing acc: 74.00% ( 7400/10000), training loss: 0.77, training acc: 73.32%
[24/11/24 14:21:45, INFO, CSE_FSL_main.py:main():269]  > R 104, agg. final model, testing loss: 0.74, testing acc: 73.99% ( 7399/10000), training loss: 0.76, training acc: 73.18%
[24/11/24 14:22:10, INFO, CSE_FSL_main.py:main():269]  > R 105, agg. final model, testing loss: 0.73, testing acc: 74.69% ( 7469/10000), training loss: 0.76, training acc: 73.39%
[24/11/24 14:22:36, INFO, CSE_FSL_main.py:main():269]  > R 106, agg. final model, testing loss: 0.74, testing acc: 74.54% ( 7454/10000), training loss: 0.78, training acc: 72.58%
[24/11/24 14:23:01, INFO, CSE_FSL_main.py:main():269]  > R 107, agg. final model, testing loss: 0.75, testing acc: 74.24% ( 7424/10000), training loss: 0.76, training acc: 73.42%
[24/11/24 14:23:27, INFO, CSE_FSL_main.py:main():269]  > R 108, agg. final model, testing loss: 0.73, testing acc: 75.16% ( 7516/10000), training loss: 0.75, training acc: 73.41%
[24/11/24 14:23:52, INFO, CSE_FSL_main.py:main():269]  > R 109, agg. final model, testing loss: 0.75, testing acc: 74.16% ( 7416/10000), training loss: 0.76, training acc: 73.29%
[24/11/24 14:24:18, INFO, CSE_FSL_main.py:main():269]  > R 110, agg. final model, testing loss: 0.73, testing acc: 74.96% ( 7496/10000), training loss: 0.74, training acc: 73.80%
[24/11/24 14:24:43, INFO, CSE_FSL_main.py:main():269]  > R 111, agg. final model, testing loss: 0.73, testing acc: 74.80% ( 7480/10000), training loss: 0.73, training acc: 74.30%
[24/11/24 14:25:09, INFO, CSE_FSL_main.py:main():269]  > R 112, agg. final model, testing loss: 0.74, testing acc: 74.38% ( 7438/10000), training loss: 0.75, training acc: 73.54%
[24/11/24 14:25:34, INFO, CSE_FSL_main.py:main():269]  > R 113, agg. final model, testing loss: 0.74, testing acc: 74.74% ( 7474/10000), training loss: 0.73, training acc: 74.27%
[24/11/24 14:26:00, INFO, CSE_FSL_main.py:main():269]  > R 114, agg. final model, testing loss: 0.75, testing acc: 74.61% ( 7461/10000), training loss: 0.75, training acc: 73.42%
[24/11/24 14:26:25, INFO, CSE_FSL_main.py:main():269]  > R 115, agg. final model, testing loss: 0.74, testing acc: 74.66% ( 7466/10000), training loss: 0.75, training acc: 73.77%
[24/11/24 14:26:51, INFO, CSE_FSL_main.py:main():269]  > R 116, agg. final model, testing loss: 0.74, testing acc: 74.56% ( 7456/10000), training loss: 0.74, training acc: 73.76%
[24/11/24 14:27:16, INFO, CSE_FSL_main.py:main():269]  > R 117, agg. final model, testing loss: 0.72, testing acc: 75.14% ( 7514/10000), training loss: 0.73, training acc: 74.27%
[24/11/24 14:27:42, INFO, CSE_FSL_main.py:main():269]  > R 118, agg. final model, testing loss: 0.73, testing acc: 75.08% ( 7508/10000), training loss: 0.72, training acc: 74.53%
[24/11/24 14:28:08, INFO, CSE_FSL_main.py:main():269]  > R 119, agg. final model, testing loss: 0.73, testing acc: 75.14% ( 7514/10000), training loss: 0.73, training acc: 74.48%
[24/11/24 14:28:33, INFO, CSE_FSL_main.py:main():269]  > R 120, agg. final model, testing loss: 0.72, testing acc: 74.64% ( 7464/10000), training loss: 0.72, training acc: 74.80%
[24/11/24 14:28:59, INFO, CSE_FSL_main.py:main():269]  > R 121, agg. final model, testing loss: 0.72, testing acc: 75.12% ( 7512/10000), training loss: 0.73, training acc: 74.79%
[24/11/24 14:29:24, INFO, CSE_FSL_main.py:main():269]  > R 122, agg. final model, testing loss: 0.73, testing acc: 74.78% ( 7478/10000), training loss: 0.72, training acc: 74.67%
[24/11/24 14:29:50, INFO, CSE_FSL_main.py:main():269]  > R 123, agg. final model, testing loss: 0.72, testing acc: 75.37% ( 7537/10000), training loss: 0.71, training acc: 74.98%
[24/11/24 14:30:15, INFO, CSE_FSL_main.py:main():269]  > R 124, agg. final model, testing loss: 0.72, testing acc: 75.54% ( 7554/10000), training loss: 0.72, training acc: 74.54%
[24/11/24 14:30:41, INFO, CSE_FSL_main.py:main():269]  > R 125, agg. final model, testing loss: 0.73, testing acc: 74.84% ( 7484/10000), training loss: 0.70, training acc: 75.22%
[24/11/24 14:31:07, INFO, CSE_FSL_main.py:main():269]  > R 126, agg. final model, testing loss: 0.73, testing acc: 74.81% ( 7481/10000), training loss: 0.72, training acc: 74.47%
[24/11/24 14:31:32, INFO, CSE_FSL_main.py:main():269]  > R 127, agg. final model, testing loss: 0.72, testing acc: 75.16% ( 7516/10000), training loss: 0.71, training acc: 74.93%
[24/11/24 14:31:58, INFO, CSE_FSL_main.py:main():269]  > R 128, agg. final model, testing loss: 0.74, testing acc: 74.82% ( 7482/10000), training loss: 0.72, training acc: 74.86%
[24/11/24 14:32:23, INFO, CSE_FSL_main.py:main():269]  > R 129, agg. final model, testing loss: 0.73, testing acc: 74.96% ( 7496/10000), training loss: 0.71, training acc: 75.18%
[24/11/24 14:32:49, INFO, CSE_FSL_main.py:main():269]  > R 130, agg. final model, testing loss: 0.72, testing acc: 75.26% ( 7526/10000), training loss: 0.70, training acc: 75.33%
[24/11/24 14:33:14, INFO, CSE_FSL_main.py:main():269]  > R 131, agg. final model, testing loss: 0.73, testing acc: 75.32% ( 7532/10000), training loss: 0.70, training acc: 75.29%
[24/11/24 14:33:40, INFO, CSE_FSL_main.py:main():269]  > R 132, agg. final model, testing loss: 0.71, testing acc: 75.62% ( 7562/10000), training loss: 0.68, training acc: 76.08%
[24/11/24 14:34:06, INFO, CSE_FSL_main.py:main():269]  > R 133, agg. final model, testing loss: 0.73, testing acc: 75.34% ( 7534/10000), training loss: 0.71, training acc: 74.95%
[24/11/24 14:34:31, INFO, CSE_FSL_main.py:main():269]  > R 134, agg. final model, testing loss: 0.72, testing acc: 74.94% ( 7494/10000), training loss: 0.70, training acc: 75.38%
[24/11/24 14:34:57, INFO, CSE_FSL_main.py:main():269]  > R 135, agg. final model, testing loss: 0.71, testing acc: 75.50% ( 7550/10000), training loss: 0.69, training acc: 76.03%
[24/11/24 14:35:22, INFO, CSE_FSL_main.py:main():269]  > R 136, agg. final model, testing loss: 0.73, testing acc: 74.90% ( 7490/10000), training loss: 0.70, training acc: 75.27%
[24/11/24 14:35:48, INFO, CSE_FSL_main.py:main():269]  > R 137, agg. final model, testing loss: 0.70, testing acc: 75.66% ( 7566/10000), training loss: 0.70, training acc: 75.26%
[24/11/24 14:36:14, INFO, CSE_FSL_main.py:main():269]  > R 138, agg. final model, testing loss: 0.72, testing acc: 75.17% ( 7517/10000), training loss: 0.71, training acc: 75.22%
[24/11/24 14:36:39, INFO, CSE_FSL_main.py:main():269]  > R 139, agg. final model, testing loss: 0.71, testing acc: 75.55% ( 7555/10000), training loss: 0.68, training acc: 76.02%
[24/11/24 14:37:05, INFO, CSE_FSL_main.py:main():269]  > R 140, agg. final model, testing loss: 0.71, testing acc: 75.51% ( 7551/10000), training loss: 0.70, training acc: 75.70%
[24/11/24 14:37:30, INFO, CSE_FSL_main.py:main():269]  > R 141, agg. final model, testing loss: 0.71, testing acc: 75.47% ( 7547/10000), training loss: 0.68, training acc: 75.94%
[24/11/24 14:37:56, INFO, CSE_FSL_main.py:main():269]  > R 142, agg. final model, testing loss: 0.72, testing acc: 75.55% ( 7555/10000), training loss: 0.69, training acc: 75.79%
[24/11/24 14:38:22, INFO, CSE_FSL_main.py:main():269]  > R 143, agg. final model, testing loss: 0.72, testing acc: 75.39% ( 7539/10000), training loss: 0.70, training acc: 75.31%
[24/11/24 14:38:47, INFO, CSE_FSL_main.py:main():269]  > R 144, agg. final model, testing loss: 0.71, testing acc: 76.00% ( 7600/10000), training loss: 0.69, training acc: 75.86%
[24/11/24 14:39:13, INFO, CSE_FSL_main.py:main():269]  > R 145, agg. final model, testing loss: 0.72, testing acc: 75.40% ( 7540/10000), training loss: 0.68, training acc: 75.90%
[24/11/24 14:39:39, INFO, CSE_FSL_main.py:main():269]  > R 146, agg. final model, testing loss: 0.70, testing acc: 75.54% ( 7554/10000), training loss: 0.68, training acc: 76.09%
[24/11/24 14:40:04, INFO, CSE_FSL_main.py:main():269]  > R 147, agg. final model, testing loss: 0.72, testing acc: 74.81% ( 7481/10000), training loss: 0.69, training acc: 75.76%
[24/11/24 14:40:30, INFO, CSE_FSL_main.py:main():269]  > R 148, agg. final model, testing loss: 0.71, testing acc: 75.61% ( 7561/10000), training loss: 0.68, training acc: 76.03%
[24/11/24 14:40:55, INFO, CSE_FSL_main.py:main():269]  > R 149, agg. final model, testing loss: 0.70, testing acc: 76.25% ( 7625/10000), training loss: 0.66, training acc: 76.80%
[24/11/24 14:41:21, INFO, CSE_FSL_main.py:main():269]  > R 150, agg. final model, testing loss: 0.72, testing acc: 75.61% ( 7561/10000), training loss: 0.69, training acc: 75.98%
[24/11/24 14:41:47, INFO, CSE_FSL_main.py:main():269]  > R 151, agg. final model, testing loss: 0.70, testing acc: 75.60% ( 7560/10000), training loss: 0.67, training acc: 76.55%
[24/11/24 14:42:13, INFO, CSE_FSL_main.py:main():269]  > R 152, agg. final model, testing loss: 0.72, testing acc: 75.37% ( 7537/10000), training loss: 0.67, training acc: 76.15%
[24/11/24 14:42:38, INFO, CSE_FSL_main.py:main():269]  > R 153, agg. final model, testing loss: 0.72, testing acc: 75.46% ( 7546/10000), training loss: 0.67, training acc: 76.32%
[24/11/24 14:43:04, INFO, CSE_FSL_main.py:main():269]  > R 154, agg. final model, testing loss: 0.72, testing acc: 75.22% ( 7522/10000), training loss: 0.67, training acc: 76.36%
[24/11/24 14:43:29, INFO, CSE_FSL_main.py:main():269]  > R 155, agg. final model, testing loss: 0.72, testing acc: 76.15% ( 7615/10000), training loss: 0.69, training acc: 75.86%
[24/11/24 14:43:55, INFO, CSE_FSL_main.py:main():269]  > R 156, agg. final model, testing loss: 0.70, testing acc: 76.00% ( 7600/10000), training loss: 0.69, training acc: 75.66%
[24/11/24 14:44:20, INFO, CSE_FSL_main.py:main():269]  > R 157, agg. final model, testing loss: 0.73, testing acc: 75.59% ( 7559/10000), training loss: 0.68, training acc: 76.09%
[24/11/24 14:44:46, INFO, CSE_FSL_main.py:main():269]  > R 158, agg. final model, testing loss: 0.72, testing acc: 75.83% ( 7583/10000), training loss: 0.66, training acc: 76.69%
[24/11/24 14:45:12, INFO, CSE_FSL_main.py:main():269]  > R 159, agg. final model, testing loss: 0.72, testing acc: 76.02% ( 7602/10000), training loss: 0.66, training acc: 76.65%
[24/11/24 14:45:37, INFO, CSE_FSL_main.py:main():269]  > R 160, agg. final model, testing loss: 0.71, testing acc: 76.20% ( 7620/10000), training loss: 0.67, training acc: 76.42%
[24/11/24 14:46:03, INFO, CSE_FSL_main.py:main():269]  > R 161, agg. final model, testing loss: 0.72, testing acc: 75.61% ( 7561/10000), training loss: 0.66, training acc: 77.25%
[24/11/24 14:46:28, INFO, CSE_FSL_main.py:main():269]  > R 162, agg. final model, testing loss: 0.71, testing acc: 76.02% ( 7602/10000), training loss: 0.66, training acc: 76.71%
[24/11/24 14:46:54, INFO, CSE_FSL_main.py:main():269]  > R 163, agg. final model, testing loss: 0.72, testing acc: 75.98% ( 7598/10000), training loss: 0.66, training acc: 76.87%
[24/11/24 14:47:20, INFO, CSE_FSL_main.py:main():269]  > R 164, agg. final model, testing loss: 0.72, testing acc: 75.95% ( 7595/10000), training loss: 0.66, training acc: 76.70%
[24/11/24 14:47:45, INFO, CSE_FSL_main.py:main():269]  > R 165, agg. final model, testing loss: 0.72, testing acc: 75.71% ( 7571/10000), training loss: 0.67, training acc: 76.61%
[24/11/24 14:48:11, INFO, CSE_FSL_main.py:main():269]  > R 166, agg. final model, testing loss: 0.72, testing acc: 75.70% ( 7570/10000), training loss: 0.66, training acc: 77.11%
[24/11/24 14:48:36, INFO, CSE_FSL_main.py:main():269]  > R 167, agg. final model, testing loss: 0.71, testing acc: 76.12% ( 7612/10000), training loss: 0.65, training acc: 77.29%
[24/11/24 14:49:02, INFO, CSE_FSL_main.py:main():269]  > R 168, agg. final model, testing loss: 0.71, testing acc: 76.37% ( 7637/10000), training loss: 0.66, training acc: 76.79%
[24/11/24 14:49:28, INFO, CSE_FSL_main.py:main():269]  > R 169, agg. final model, testing loss: 0.72, testing acc: 75.80% ( 7580/10000), training loss: 0.65, training acc: 77.37%
[24/11/24 14:49:53, INFO, CSE_FSL_main.py:main():269]  > R 170, agg. final model, testing loss: 0.71, testing acc: 75.86% ( 7586/10000), training loss: 0.65, training acc: 76.95%
[24/11/24 14:50:19, INFO, CSE_FSL_main.py:main():269]  > R 171, agg. final model, testing loss: 0.71, testing acc: 75.90% ( 7590/10000), training loss: 0.65, training acc: 77.07%
[24/11/24 14:50:44, INFO, CSE_FSL_main.py:main():269]  > R 172, agg. final model, testing loss: 0.71, testing acc: 75.72% ( 7572/10000), training loss: 0.64, training acc: 77.25%
[24/11/24 14:51:10, INFO, CSE_FSL_main.py:main():269]  > R 173, agg. final model, testing loss: 0.72, testing acc: 76.00% ( 7600/10000), training loss: 0.65, training acc: 77.20%
[24/11/24 14:51:35, INFO, CSE_FSL_main.py:main():269]  > R 174, agg. final model, testing loss: 0.71, testing acc: 75.82% ( 7582/10000), training loss: 0.65, training acc: 77.24%
[24/11/24 14:52:01, INFO, CSE_FSL_main.py:main():269]  > R 175, agg. final model, testing loss: 0.72, testing acc: 75.17% ( 7517/10000), training loss: 0.65, training acc: 77.16%
[24/11/24 14:52:26, INFO, CSE_FSL_main.py:main():269]  > R 176, agg. final model, testing loss: 0.72, testing acc: 75.74% ( 7574/10000), training loss: 0.67, training acc: 76.79%
[24/11/24 14:52:52, INFO, CSE_FSL_main.py:main():269]  > R 177, agg. final model, testing loss: 0.71, testing acc: 75.85% ( 7585/10000), training loss: 0.64, training acc: 77.23%
[24/11/24 14:53:17, INFO, CSE_FSL_main.py:main():269]  > R 178, agg. final model, testing loss: 0.72, testing acc: 75.76% ( 7576/10000), training loss: 0.66, training acc: 76.43%
[24/11/24 14:53:43, INFO, CSE_FSL_main.py:main():269]  > R 179, agg. final model, testing loss: 0.71, testing acc: 76.24% ( 7624/10000), training loss: 0.65, training acc: 77.35%
[24/11/24 14:54:08, INFO, CSE_FSL_main.py:main():269]  > R 180, agg. final model, testing loss: 0.72, testing acc: 75.56% ( 7556/10000), training loss: 0.65, training acc: 77.42%
[24/11/24 14:54:34, INFO, CSE_FSL_main.py:main():269]  > R 181, agg. final model, testing loss: 0.70, testing acc: 76.24% ( 7624/10000), training loss: 0.64, training acc: 77.54%
[24/11/24 14:54:59, INFO, CSE_FSL_main.py:main():269]  > R 182, agg. final model, testing loss: 0.70, testing acc: 75.99% ( 7599/10000), training loss: 0.64, training acc: 77.72%
[24/11/24 14:55:25, INFO, CSE_FSL_main.py:main():269]  > R 183, agg. final model, testing loss: 0.71, testing acc: 76.01% ( 7601/10000), training loss: 0.63, training acc: 77.79%
[24/11/24 14:55:51, INFO, CSE_FSL_main.py:main():269]  > R 184, agg. final model, testing loss: 0.72, testing acc: 75.75% ( 7575/10000), training loss: 0.64, training acc: 77.56%
[24/11/24 14:56:16, INFO, CSE_FSL_main.py:main():269]  > R 185, agg. final model, testing loss: 0.71, testing acc: 76.51% ( 7651/10000), training loss: 0.64, training acc: 77.67%
[24/11/24 14:56:41, INFO, CSE_FSL_main.py:main():269]  > R 186, agg. final model, testing loss: 0.71, testing acc: 76.17% ( 7617/10000), training loss: 0.63, training acc: 77.87%
[24/11/24 14:57:07, INFO, CSE_FSL_main.py:main():269]  > R 187, agg. final model, testing loss: 0.71, testing acc: 75.81% ( 7581/10000), training loss: 0.64, training acc: 77.79%
[24/11/24 14:57:32, INFO, CSE_FSL_main.py:main():269]  > R 188, agg. final model, testing loss: 0.72, testing acc: 76.08% ( 7608/10000), training loss: 0.63, training acc: 77.85%
[24/11/24 14:57:58, INFO, CSE_FSL_main.py:main():269]  > R 189, agg. final model, testing loss: 0.71, testing acc: 76.30% ( 7630/10000), training loss: 0.63, training acc: 78.03%
[24/11/24 14:58:23, INFO, CSE_FSL_main.py:main():269]  > R 190, agg. final model, testing loss: 0.72, testing acc: 76.08% ( 7608/10000), training loss: 0.65, training acc: 77.51%
[24/11/24 14:58:49, INFO, CSE_FSL_main.py:main():269]  > R 191, agg. final model, testing loss: 0.70, testing acc: 75.99% ( 7599/10000), training loss: 0.64, training acc: 77.45%
[24/11/24 14:59:14, INFO, CSE_FSL_main.py:main():269]  > R 192, agg. final model, testing loss: 0.72, testing acc: 75.93% ( 7593/10000), training loss: 0.63, training acc: 77.91%
[24/11/24 14:59:40, INFO, CSE_FSL_main.py:main():269]  > R 193, agg. final model, testing loss: 0.70, testing acc: 76.89% ( 7689/10000), training loss: 0.64, training acc: 77.61%
[24/11/24 15:00:05, INFO, CSE_FSL_main.py:main():269]  > R 194, agg. final model, testing loss: 0.73, testing acc: 75.98% ( 7598/10000), training loss: 0.65, training acc: 77.32%
[24/11/24 15:00:31, INFO, CSE_FSL_main.py:main():269]  > R 195, agg. final model, testing loss: 0.72, testing acc: 75.72% ( 7572/10000), training loss: 0.63, training acc: 77.84%
[24/11/24 15:00:56, INFO, CSE_FSL_main.py:main():269]  > R 196, agg. final model, testing loss: 0.70, testing acc: 76.35% ( 7635/10000), training loss: 0.62, training acc: 78.17%
[24/11/24 15:01:22, INFO, CSE_FSL_main.py:main():269]  > R 197, agg. final model, testing loss: 0.70, testing acc: 76.58% ( 7658/10000), training loss: 0.62, training acc: 78.11%
[24/11/24 15:01:47, INFO, CSE_FSL_main.py:main():269]  > R 198, agg. final model, testing loss: 0.70, testing acc: 76.67% ( 7667/10000), training loss: 0.64, training acc: 77.52%
[24/11/24 15:02:13, INFO, CSE_FSL_main.py:main():269]  > R 199, agg. final model, testing loss: 0.71, testing acc: 76.05% ( 7605/10000), training loss: 0.64, training acc: 77.65%
[24/11/24 15:02:13, INFO, CSE_FSL_main.py:main():271] The total running time for all rounds is 5114.14 seconds
[24/11/24 15:02:13, INFO, CSE_FSL_main.py:main():281] [NOTICE] Saved results to '../saves/cifar-iid-K3U3E1BR1-200-241124-133657/results.json'.
[24/11/24 15:02:14, INFO, CSE_FSL_main.py:main():293] Testing accuracy: [0.1722, 0.2953, 0.3444, 0.3632, 0.3931, 0.4042, 0.4184, 0.4456, 0.4447, 0.4671, 0.4769, 0.4832, 0.4906, 0.4943, 0.5046, 0.5267, 0.5224, 0.5302, 0.5373, 0.551, 0.5508, 0.5595, 0.5682, 0.5743, 0.5773, 0.5844, 0.5937, 0.6024, 0.616, 0.6163, 0.6159, 0.6272, 0.6265, 0.6352, 0.6389, 0.6507, 0.6515, 0.6572, 0.6571, 0.6675, 0.6647, 0.6637, 0.6629, 0.675, 0.6799, 0.6791, 0.6803, 0.6809, 0.6902, 0.689, 0.6912, 0.6958, 0.6935, 0.7026, 0.7041, 0.7019, 0.7048, 0.7032, 0.7099, 0.6975, 0.7111, 0.7128, 0.7079, 0.7192, 0.7132, 0.7193, 0.7167, 0.7195, 0.7184, 0.7216, 0.7258, 0.7207, 0.7236, 0.7333, 0.7259, 0.725, 0.7335, 0.7214, 0.7315, 0.7305, 0.7314, 0.7348, 0.7366, 0.7358, 0.7342, 0.7329, 0.7348, 0.7419, 0.7296, 0.7384, 0.741, 0.7387, 0.7332, 0.737, 0.7358, 0.7477, 0.742, 0.743, 0.7408, 0.7386, 0.7477, 0.7411, 0.7442, 0.74, 0.7399, 0.7469, 0.7454, 0.7424, 0.7516, 0.7416, 0.7496, 0.748, 0.7438, 0.7474, 0.7461, 0.7466, 0.7456, 0.7514, 0.7508, 0.7514, 0.7464, 0.7512, 0.7478, 0.7537, 0.7554, 0.7484, 0.7481, 0.7516, 0.7482, 0.7496, 0.7526, 0.7532, 0.7562, 0.7534, 0.7494, 0.755, 0.749, 0.7566, 0.7517, 0.7555, 0.7551, 0.7547, 0.7555, 0.7539, 0.76, 0.754, 0.7554, 0.7481, 0.7561, 0.7625, 0.7561, 0.756, 0.7537, 0.7546, 0.7522, 0.7615, 0.76, 0.7559, 0.7583, 0.7602, 0.762, 0.7561, 0.7602, 0.7598, 0.7595, 0.7571, 0.757, 0.7612, 0.7637, 0.758, 0.7586, 0.759, 0.7572, 0.76, 0.7582, 0.7517, 0.7574, 0.7585, 0.7576, 0.7624, 0.7556, 0.7624, 0.7599, 0.7601, 0.7575, 0.7651, 0.7617, 0.7581, 0.7608, 0.763, 0.7608, 0.7599, 0.7593, 0.7689, 0.7598, 0.7572, 0.7635, 0.7658, 0.7667, 0.7605]
[24/11/24 15:02:14, INFO, CSE_FSL_main.py:main():294] Testing loss: [2.217808125894281, 1.889048002943208, 1.773582386065133, 1.7167491958111147, 1.637528912930549, 1.5976598987096473, 1.5606561989723882, 1.517691666566873, 1.5069816127608093, 1.4622114957133425, 1.4387197056903114, 1.4221655296373972, 1.4017340518251251, 1.390745079970058, 1.3667398163034945, 1.3281380783153485, 1.316438287119322, 1.298680859276011, 1.2945823578894893, 1.258912898317168, 1.255337823795367, 1.2369157875640482, 1.2065109165408943, 1.1929248873191545, 1.193502759631676, 1.166700935061974, 1.1590121946757352, 1.132225055483323, 1.0982404479497596, 1.0992555678645266, 1.0895897368841534, 1.0643560094169424, 1.0530292716207383, 1.038980868798268, 1.020025908946991, 1.001873951169509, 0.9941763704336142, 0.9799402597584302, 0.9726569101780276, 0.9495799858358842, 0.9520964811119852, 0.9474309939372388, 0.9528496423854104, 0.9320958354805089, 0.9229710486870778, 0.9160394540315941, 0.919444281089155, 0.915138793142536, 0.8913022204290463, 0.8946291819403444, 0.8996378824680666, 0.8741749924949452, 0.8849968148183219, 0.8707579555390756, 0.8734720824640009, 0.8612220491035075, 0.8529989915558055, 0.8551791695099843, 0.8312107709389699, 0.8607450406762618, 0.8411377736284763, 0.831512494177758, 0.8447499214848385, 0.8212328002422671, 0.8216193046750901, 0.813775675960734, 0.8173223756536653, 0.8053689025625398, 0.8128127108646345, 0.79610806250874, 0.79354940185064, 0.7970995767207085, 0.8051764338831359, 0.7924648561055148, 0.7888780975643592, 0.7799038373971288, 0.7749149407012553, 0.8025687872609005, 0.7727774894690211, 0.7726896933362454, 0.7815857386287255, 0.7719968127298958, 0.7682639586774609, 0.7605033592332767, 0.7689252608939062, 0.7749432740332205, 0.7713656689547286, 0.7469233485716807, 0.7745597883115841, 0.7574694918680794, 0.7580650290356407, 0.7621384851540192, 0.7596188413945935, 0.765383773589436, 0.759095958139323, 0.7367522531672369, 0.7448865646802927, 0.7431223965898345, 0.7475309070152573, 0.741232076400443, 0.7397438823422299, 0.7447037187558186, 0.7388123055047626, 0.745693782839594, 0.7430152444145347, 0.7340544020827813, 0.742157551683957, 0.746378422915181, 0.7323809062378316, 0.7512862882282161, 0.7278608049772963, 0.7316708772242824, 0.7443197218677665, 0.7379588345183602, 0.7520834547054919, 0.7403302419034741, 0.7373411048062241, 0.7195572558837601, 0.7252959311008453, 0.7308403178106381, 0.7246790396261819, 0.7231129045727887, 0.7303190861321702, 0.7214949874183799, 0.7247164951095099, 0.7275182514251033, 0.7339501946787291, 0.71933799001235, 0.7367911987666842, 0.7316372945338865, 0.7210801911504963, 0.7300206517116933, 0.7093861582158487, 0.7261076758179483, 0.7230473481401613, 0.7103132960162585, 0.7266453327257422, 0.7035303564765786, 0.7199478024923349, 0.7139344196530837, 0.7064255128932905, 0.7130717107012302, 0.7163787752012664, 0.7192873811420006, 0.7098792878132832, 0.7156551619873771, 0.7045233426969263, 0.7191375844840762, 0.7052435920208315, 0.6957603394985199, 0.7205918103079253, 0.7013734895971757, 0.7163512133344819, 0.7175084899497938, 0.7195548716979691, 0.7213308558433871, 0.7049400357505943, 0.7268305496324466, 0.7170839822745021, 0.7168760235551037, 0.7076876812343356, 0.7169691958004916, 0.7148586356941657, 0.7189570978472505, 0.7151053321512439, 0.7161566298219222, 0.7187864388091655, 0.708020589774168, 0.7119551070883304, 0.7197725953935068, 0.7088348850419249, 0.7142794245406042, 0.7070639967163906, 0.7170528554463689, 0.7073977714097952, 0.7171355531185488, 0.7222125518925583, 0.7072486643549762, 0.7181752554223507, 0.7091662763040277, 0.7188797623296327, 0.7044169899029068, 0.7005072500132308, 0.7065835380101506, 0.721327647378173, 0.7077566868142237, 0.706785577761976, 0.7142234108870542, 0.7175987302502499, 0.7061222968976709, 0.7230321783808213, 0.7025110151948808, 0.7174517949925193, 0.6977871305580381, 0.7265044001838828, 0.7197383427167241, 0.7038183740422695, 0.7032224132290369, 0.7049121509624433, 0.7086037951934187]
[24/11/24 15:02:14, INFO, CSE_FSL_main.py:main():295] Training accuracy: [0.15260610424416976, 0.26035041401656067, 0.3001120044801792, 0.31341253650146006, 0.3380135205408216, 0.3655546221848874, 0.38217528701148046, 0.39773590943637743, 0.39731589263570544, 0.4158766350654026, 0.42379695187807515, 0.4332373294931797, 0.43841753670146805, 0.4453778151126045, 0.4576983079323173, 0.4733789351574063, 0.47981919276771073, 0.4888195527821113, 0.484299371974879, 0.4980799231969279, 0.4931397255890236, 0.5095203808152327, 0.5171206848273932, 0.5260410416416657, 0.5257210288411537, 0.5385215408616345, 0.5432217288691548, 0.5459418376735069, 0.561822472898916, 0.5656626265050602, 0.5674026961078443, 0.5752430097203888, 0.5855834233369335, 0.5883235329413177, 0.5942037681507261, 0.6000840033601345, 0.5974638985559423, 0.6110044401776071, 0.6138845553822153, 0.6196647865914636, 0.626285051402056, 0.6277051082043281, 0.6290851634065363, 0.6281451258050322, 0.6341853674146966, 0.6428257130285211, 0.640905636225449, 0.6453058122324893, 0.6500260010400416, 0.6531461258450338, 0.6452858114324573, 0.6553662146485859, 0.6570662826513061, 0.6584863394535782, 0.6656866274650987, 0.6685467418696748, 0.670546821872875, 0.6703468138725549, 0.6759270370814833, 0.6605464218568743, 0.6704268170726829, 0.6757270290811632, 0.6810872434897396, 0.6855474218968759, 0.6838473538941557, 0.687967518700748, 0.6887875515020601, 0.686267450698028, 0.68748749949998, 0.6950678027121084, 0.6968278731149246, 0.6999879995199808, 0.6935877435097404, 0.6941277651106045, 0.6973478939157566, 0.7052082083283331, 0.7077883115324612, 0.702548101924077, 0.7086083443337734, 0.7079683187327493, 0.7092083683347334, 0.7097883915356614, 0.7114084563382536, 0.7173686947477899, 0.7133885355414217, 0.7160886435457419, 0.7152486099443978, 0.7166686667466698, 0.7145285811432457, 0.7152686107444298, 0.7218288731549262, 0.7207488299531981, 0.7232689307572303, 0.718328733149326, 0.7238289531581263, 0.7293091723668946, 0.7294891795671827, 0.7261490459618385, 0.7336093443737749, 0.7274490979639185, 0.7322492899715989, 0.7306092243689748, 0.7309492379695188, 0.733189327573103, 0.7318292731709268, 0.7339093563742549, 0.7257690307612304, 0.7342093683747349, 0.734129365174607, 0.732929317172687, 0.7379695187807512, 0.7429897195887836, 0.735369414776591, 0.7427497099883995, 0.734189367574703, 0.7377495099803992, 0.7376295051802072, 0.7427297091883676, 0.7453098123924957, 0.7448497939917597, 0.7480099203968159, 0.7479099163966558, 0.7466898675947038, 0.749809992399696, 0.7454298171926877, 0.7521700868034722, 0.7447297891915676, 0.7492899715988639, 0.748609944397776, 0.7517700708028321, 0.7532901316052643, 0.7528701148045922, 0.7607704308172327, 0.749489979599184, 0.7537901516060642, 0.7602704108164327, 0.7526501060042402, 0.7525701028041122, 0.7521700868034722, 0.7601504060162406, 0.7569502780111205, 0.7594103764150566, 0.7579103164126565, 0.7530501220048802, 0.7585703428137125, 0.7590103604144166, 0.7608704348173927, 0.7575503020120805, 0.7602904116164647, 0.7680107204288171, 0.7597703908156326, 0.765490619624785, 0.7615304612184487, 0.7632105284211368, 0.7636305452218088, 0.7586303452138086, 0.7565702628105124, 0.7609304372174887, 0.7669106764270571, 0.7664906596263851, 0.7642305692227689, 0.7725309012360494, 0.7670506820272811, 0.7687107484299373, 0.7669506780271211, 0.7660506420256811, 0.7711108444337773, 0.7728909156366255, 0.7678907156286251, 0.7736509460378415, 0.7694907796311853, 0.7707308292331694, 0.7724908996359854, 0.7719508780351214, 0.7724108964358575, 0.7715708628345134, 0.7678707148285931, 0.7723308932357295, 0.764330573222929, 0.7734709388375535, 0.7741909676387055, 0.7753510140405616, 0.7772110884435377, 0.7778511140445618, 0.7755710228409136, 0.7767310692427697, 0.7787311492459699, 0.7778911156446258, 0.7784911396455858, 0.7802912116484659, 0.7751110044401776, 0.7744909796391856, 0.7791111644465779, 0.7760710428417137, 0.7731709268370734, 0.7783511340453618, 0.7817312692507701, 0.781071242849714, 0.7752110084403376, 0.7765110604424177]
[24/11/24 15:02:14, INFO, CSE_FSL_main.py:main():296] Training loss: [2.2339545084926615, 1.9694112011494527, 1.8727305150820706, 1.828562636411827, 1.7698168648411603, 1.706451126334018, 1.6765755918493102, 1.6435793641262686, 1.633797294917604, 1.59364185381785, 1.5710773188952574, 1.5439723951519293, 1.534694703784001, 1.5182153220091763, 1.4965909719467163, 1.4526589593207866, 1.4442980098360367, 1.4176424080482268, 1.4260657437278417, 1.3881115573659804, 1.3931749388765136, 1.360521740585793, 1.3382230634604397, 1.3216849768738104, 1.3122896298804052, 1.2901837831841776, 1.2801541161294505, 1.26406600184113, 1.220184187397702, 1.2176098047018657, 1.2147804782287461, 1.1860977772234658, 1.1683213396836782, 1.15563258596959, 1.1413579771233575, 1.1201882213733274, 1.1336584531017235, 1.1007362957522462, 1.0897785764917467, 1.0700797065523744, 1.055539041530085, 1.0537263370348904, 1.0481797453708017, 1.0517764766404343, 1.0338284127584851, 1.0128319425740617, 1.0176988171257135, 1.0102677528791453, 0.9856423479303452, 0.9849696277662088, 1.0000185666193488, 0.9713036624226558, 0.9750221829681299, 0.9736669829480218, 0.9535897635018249, 0.9401119352903682, 0.9443136500644926, 0.9314624271320022, 0.9203351391787444, 0.9615572100983928, 0.9337883206420879, 0.912286129009936, 0.9104385888606841, 0.8913126657633987, 0.9075680193100267, 0.8893682979445421, 0.8875421105147014, 0.8906902305345802, 0.884917762746641, 0.8633019701215147, 0.8662498054916925, 0.8555505081594142, 0.867958498668428, 0.8595747395629495, 0.8613287906610329, 0.8400498261585188, 0.8329767300427415, 0.8532868936164992, 0.829887441703078, 0.8347899701455774, 0.83044705196798, 0.8260386769704843, 0.8227025566210273, 0.8002046171490472, 0.8126900039859704, 0.8121140647783838, 0.8178089347504477, 0.8046849329052991, 0.8172179249710102, 0.8066120117371925, 0.793436479477482, 0.7986730546441697, 0.7874058392515013, 0.7959339808265065, 0.789321541027865, 0.7718760155842808, 0.7686597559288257, 0.7784791006386735, 0.7609444022481981, 0.7760302745962264, 0.7603154660181235, 0.7628800309341373, 0.7624461446857937, 0.7652376940232197, 0.7638482582629789, 0.758595683040813, 0.7780064877511285, 0.7614933675482073, 0.7549801558331982, 0.7646919708822216, 0.74446848542939, 0.73207209446958, 0.7522830900951802, 0.7321784497824031, 0.7538985726790877, 0.746520668723201, 0.7420241408069018, 0.7325019830359151, 0.7220600173066893, 0.7276618744580801, 0.7175040662137, 0.7269152866216713, 0.7191219269167679, 0.7106998066865761, 0.7232597784989966, 0.7035898943893782, 0.7218018015680726, 0.7146634497411986, 0.7160438569902464, 0.713065629090365, 0.7010594492650214, 0.7031458039926816, 0.683993374194201, 0.7080785777732617, 0.7028456551731391, 0.6859246189054339, 0.7041532313095704, 0.698219097449276, 0.7057067345420216, 0.6846535574388868, 0.6970566276830571, 0.6847351358743721, 0.6917325302238077, 0.7009702324867249, 0.6855087557063455, 0.6815979512593219, 0.6822824478907743, 0.6896132013118298, 0.6806963908156669, 0.6608088589048264, 0.689509999130215, 0.6728523936283801, 0.6739207796619745, 0.6706033210262997, 0.6710241305009099, 0.6873036883107881, 0.6906796151596778, 0.6802739711814861, 0.6614231706878915, 0.6645638730386438, 0.6743328365812471, 0.6580602224091537, 0.6607466688896256, 0.6565213675110698, 0.6649750408173821, 0.670810524668099, 0.6565581908966142, 0.6524846900358758, 0.660892436446731, 0.6494094618707517, 0.6540530139708337, 0.6534120700589876, 0.6441896093710688, 0.652184309395215, 0.6510200427688715, 0.6545530351367009, 0.6674056873673397, 0.6435439494881617, 0.6592043096782597, 0.6462380167940494, 0.6460413028114018, 0.6378481658815428, 0.6366586710963844, 0.6345165901208348, 0.6439067116978817, 0.6376942613045982, 0.629413535804239, 0.637123038447237, 0.629826119913703, 0.6275043979704228, 0.6451588204798807, 0.641925391805081, 0.6348448157613817, 0.6440307130947065, 0.645136815901021, 0.6334801734858797, 0.6244948882486377, 0.6238001767763958, 0.6369004756894731, 0.6366283793485802]
